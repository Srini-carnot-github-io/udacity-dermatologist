{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project\n",
    "## Machine Learning Engineer Nanodegree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Pics/MLSb-T.png\" width=\"160\">\n",
    "<br><br>\n",
    "<center><u><H1>Cancer Detection with Keras</H1></u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "set_session(sess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.datasets import mnist\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 total skin cancer categories.\n",
      "There are 14307 total skin images.\n",
      "\n",
      "There are 13557 training skin cancer images.\n",
      "There are 150 validation skin cancer images.\n",
      "There are 600 test skin cancer images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    cancer_files = np.array(data['filenames'])\n",
    "    cancer_targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    return cancer_files, cancer_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dermatologist-ai/data/train/train')\n",
    "valid_files, valid_targets = load_dataset('dermatologist-ai/data/valid/valid')\n",
    "test_files, test_targets = load_dataset('dermatologist-ai/data/test/test')\n",
    "\n",
    "# load list of dog names\n",
    "cancer_names = [item[20:-1] for item in sorted(glob(\"dermatologist-ai/data/train/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total skin cancer categories.' % len(cancer_names))\n",
    "print('There are %s total skin images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training skin cancer images.' % len(train_files))\n",
    "print('There are %d validation skin cancer images.' % len(valid_files))\n",
    "print('There are %d test skin cancer images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13557, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13557/13557 [24:27<00:00,  9.24it/s] \n",
      "100%|██████████| 150/150 [00:35<00:00,  4.88it/s]\n",
      "100%|██████████| 600/600 [03:39<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#Normalize the input data:\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 223, 223, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 46656)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               23328500  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 1503      \n",
      "=================================================================\n",
      "Total params: 23,340,547\n",
      "Trainable params: 23,340,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "#model.add(Dropout(0.2, input_shape=(224,224,3)))\n",
    "model.add(Conv2D(16, (2, 2), padding='valid',activation='relu',input_shape=(224,224,3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model.add(Conv2D(32, (2, 2),padding='valid',activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model.add(Conv2D(64, (2, 2), padding='valid',activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "#model.add(GlobalAveragePooling2D(data_format=None))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "  saver.restore(sess, \"saved_models/tensorvalues.ckpt\")\n",
    "  print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 222, 222, 32)      2080      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 221, 221, 64)      8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 221, 221, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 110, 110, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 774400)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               99123328  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 99,134,259\n",
      "Trainable params: 99,134,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(224,224,3)))\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Activation\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "\n",
    "# create the base pre-trained model\n",
    "#base_model = InceptionV3(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "base_model = ResNet50(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 3 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 112, 112, 64)  9472        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 112, 112, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 55, 55, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 55, 55, 64)    4160        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 55, 55, 256)   16640       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 55, 55, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 55, 55, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 55, 55, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 55, 55, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 55, 55, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 55, 55, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 55, 55, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 28, 28, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 28, 28, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 28, 28, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 28, 28, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 28, 28, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 28, 28, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 28, 28, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 14, 14, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 14, 14, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 14, 14, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 14, 14, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 14, 14, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 14, 14, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 14, 14, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 14, 14, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 14, 14, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 14, 14, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 14, 14, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 14, 14, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 14, 14, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 14, 14, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 7, 7, 512)     524800      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 7, 7, 2048)    2099200     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 2048)          0           avg_pool[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          2098176     global_average_pooling2d_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 3)             3075        dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 25,688,963\n",
      "Trainable params: 2,101,251\n",
      "Non-trainable params: 23,587,712\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "# Compile model\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.99), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_train = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True) # randomly flip images horizontally\n",
    "\n",
    "# create and configure augmented image generator\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    horizontal_flip=True) # randomly flip images horizontally\n",
    "\n",
    "# fit augmented image generator on data\n",
    "datagen_train.fit(train_tensors)\n",
    "datagen_valid.fit(valid_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13557 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1081Epoch 00000: val_loss improved from inf to 0.77131, saving model to saved_models/weights.best.resnet50.hdf5_new_3\n",
      "13557/13557 [==============================] - 114s - loss: 0.1080 - val_loss: 0.7713\n",
      "Epoch 2/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1069Epoch 00001: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1070 - val_loss: 0.7794\n",
      "Epoch 3/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1056Epoch 00002: val_loss improved from 0.77131 to 0.77118, saving model to saved_models/weights.best.resnet50.hdf5_new_3\n",
      "13557/13557 [==============================] - 114s - loss: 0.1056 - val_loss: 0.7712\n",
      "Epoch 4/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1064Epoch 00003: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1062 - val_loss: 0.7727\n",
      "Epoch 5/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1022Epoch 00004: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1027 - val_loss: 0.7766\n",
      "Epoch 6/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1041Epoch 00005: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1039 - val_loss: 0.7774\n",
      "Epoch 7/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1028Epoch 00006: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1030 - val_loss: 0.7736\n",
      "Epoch 8/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1007Epoch 00007: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1013 - val_loss: 0.7802\n",
      "Epoch 9/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.1018Epoch 00008: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.1019 - val_loss: 0.7878\n",
      "Epoch 10/10\n",
      "13312/13557 [============================>.] - ETA: 2s - loss: 0.0992Epoch 00009: val_loss did not improve\n",
      "13557/13557 [==============================] - 113s - loss: 0.0999 - val_loss: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5ad2fd048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 10\n",
    "batch_size=512\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.resnet50.hdf5_new_3', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, validation_data=(valid_tensors, valid_targets),epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)\n",
    "#model.fit_generator(datagen_train.flow(train_tensors, train_targets, batch_size=batch_size),\n",
    "#                    steps_per_epoch=train_tensors.shape[0], \n",
    "#                    epochs=epochs, verbose=1, callbacks=[checkpointer],\n",
    "#                    validation_data=datagen_valid.flow(valid_tensors, valid_targets, batch_size=batch_size),\n",
    "#                    validation_steps=valid_tensors.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d4881264f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#saved_models/weights.best.resnet50.hdf5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model.load_weights('saved_models/weights.best.inception_tf.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved_models/weights.best.resnet50.hdf5_new_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#saved_models/weights.best.resnet50.hdf5\n",
    "#model.load_weights('saved_models/weights.best.inception_tf.hdf5')\n",
    "model.load_weights('saved_models/weights.best.resnet50.hdf5_new_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 71.3333%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted cancer type for each image in test set\n",
    "cancer_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(cancer_predictions)==np.argmax(test_targets, axis=1))/len(cancer_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output .csv for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.59327774e-05   9.99882579e-01   3.14081044e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.84059966  0.11630699  0.04309333]] [ 0.  1.  0.] 0\n",
      "[[ 0.03799566  0.9573856   0.00461864]] [ 0.  1.  0.] 1\n",
      "[[  2.26508491e-02   9.77159441e-01   1.89726488e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00838031  0.98908162  0.00253805]] [ 0.  1.  0.] 1\n",
      "[[  3.32971336e-04   9.98083830e-01   1.58319320e-03]] [ 0.  0.  1.] 1\n",
      "[[ 0.04215313  0.50750589  0.45034093]] [ 0.  1.  0.] 1\n",
      "[[ 0.05376368  0.00441444  0.94182187]] [ 0.  0.  1.] 2\n",
      "[[ 0.75301737  0.23970637  0.0072763 ]] [ 0.  1.  0.] 0\n",
      "[[ 0.05995583  0.71598876  0.22405535]] [ 0.  1.  0.] 1\n",
      "[[ 0.00275743  0.98654526  0.01069736]] [ 0.  1.  0.] 1\n",
      "[[  1.74288856e-04   9.99816954e-01   8.80792868e-06]] [ 0.  1.  0.] 1\n",
      "[[ 0.10764873  0.88998735  0.00236385]] [ 0.  1.  0.] 1\n",
      "[[  2.76485545e-04   3.60111773e-01   6.39611781e-01]] [ 0.  1.  0.] 2\n",
      "[[ 0.13825947  0.8553558   0.00638475]] [ 1.  0.  0.] 1\n",
      "[[ 0.00403593  0.9890781   0.00688585]] [ 0.  1.  0.] 1\n",
      "[[ 0.01881734  0.97187084  0.00931184]] [ 0.  1.  0.] 1\n",
      "[[ 0.67361343  0.00788081  0.31850576]] [ 1.  0.  0.] 0\n",
      "[[ 0.04549249  0.94552159  0.00898595]] [ 0.  1.  0.] 1\n",
      "[[ 0.86343896  0.00889929  0.12766178]] [ 0.  1.  0.] 0\n",
      "[[ 0.01210127  0.96181786  0.02608081]] [ 0.  0.  1.] 1\n",
      "[[ 0.00460121  0.9414323   0.05396648]] [ 0.  1.  0.] 1\n",
      "[[  1.84027821e-01   8.15732241e-01   2.39862886e-04]] [ 0.  1.  0.] 1\n",
      "[[  1.83056355e-01   8.16923082e-01   2.05536144e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.12595658  0.87154931  0.00249415]] [ 0.  1.  0.] 1\n",
      "[[ 0.03941692  0.95219797  0.00838521]] [ 0.  1.  0.] 1\n",
      "[[ 0.07126807  0.8939842   0.03474769]] [ 0.  1.  0.] 1\n",
      "[[ 0.39320937  0.60098761  0.00580298]] [ 0.  1.  0.] 1\n",
      "[[ 0.13139969  0.85714597  0.01145431]] [ 0.  1.  0.] 1\n",
      "[[ 0.11815671  0.00282563  0.87901765]] [ 0.  0.  1.] 2\n",
      "[[ 0.0650675   0.93344158  0.0014909 ]] [ 0.  1.  0.] 1\n",
      "[[  6.27717600e-05   9.99937057e-01   7.03561156e-08]] [ 0.  1.  0.] 1\n",
      "[[  9.93746877e-01   1.40475936e-06   6.25167182e-03]] [ 0.  1.  0.] 0\n",
      "[[ 0.01317191  0.95388156  0.03294656]] [ 1.  0.  0.] 1\n",
      "[[ 0.01582683  0.98237395  0.0017993 ]] [ 0.  1.  0.] 1\n",
      "[[  1.02679417e-06   2.74093545e-05   9.99971509e-01]] [ 0.  0.  1.] 2\n",
      "[[  1.02999213e-03   9.98017669e-01   9.52373550e-04]] [ 1.  0.  0.] 1\n",
      "[[  7.13845110e-03   9.92307246e-01   5.54362487e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.79002553  0.15683135  0.0531432 ]] [ 0.  1.  0.] 0\n",
      "[[ 0.12096169  0.04811578  0.83092248]] [ 1.  0.  0.] 2\n",
      "[[ 0.4509902   0.44352505  0.10548477]] [ 0.  1.  0.] 0\n",
      "[[ 0.8168934   0.16816424  0.01494242]] [ 0.  1.  0.] 0\n",
      "[[ 0.02015212  0.97472996  0.00511785]] [ 0.  1.  0.] 1\n",
      "[[  1.02977676e-03   9.98109698e-01   8.60523025e-04]] [ 0.  1.  0.] 1\n",
      "[[  8.34359974e-03   9.91391301e-01   2.65061681e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.92910445  0.02902467  0.04187095]] [ 1.  0.  0.] 0\n",
      "[[ 0.0856005  0.9131909  0.0012086]] [ 0.  1.  0.] 1\n",
      "[[ 0.70596004  0.12465219  0.16938779]] [ 1.  0.  0.] 0\n",
      "[[ 0.01295861  0.91947925  0.0675621 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.11399414  0.86737579  0.01863011]] [ 0.  1.  0.] 1\n",
      "[[ 0.0704947   0.47415859  0.4553467 ]] [ 1.  0.  0.] 1\n",
      "[[ 0.00774568  0.95808214  0.03417223]] [ 0.  1.  0.] 1\n",
      "[[ 0.25658479  0.24621513  0.49720004]] [ 1.  0.  0.] 2\n",
      "[[  6.47755265e-01   3.51928473e-01   3.16316466e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.00718962  0.37572107  0.61708933]] [ 0.  1.  0.] 2\n",
      "[[  8.18276871e-03   9.91325438e-01   4.91703628e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.05644865  0.9375208   0.00603052]] [ 0.  1.  0.] 1\n",
      "[[ 0.16605291  0.83047986  0.00346717]] [ 0.  1.  0.] 1\n",
      "[[ 0.05839482  0.13401701  0.80758816]] [ 0.  0.  1.] 2\n",
      "[[ 0.00946982  0.97283155  0.01769862]] [ 0.  1.  0.] 1\n",
      "[[ 0.07867631  0.87619561  0.04512808]] [ 0.  1.  0.] 1\n",
      "[[ 0.7003594   0.24259554  0.05704512]] [ 1.  0.  0.] 0\n",
      "[[ 0.34710607  0.63606709  0.01682683]] [ 0.  1.  0.] 1\n",
      "[[ 0.00163204  0.93756336  0.06080468]] [ 0.  1.  0.] 1\n",
      "[[ 0.05899851  0.92760617  0.01339536]] [ 0.  0.  1.] 1\n",
      "[[ 0.00181024  0.98099327  0.01719641]] [ 0.  1.  0.] 1\n",
      "[[ 0.24231355  0.6608398   0.09684667]] [ 0.  1.  0.] 1\n",
      "[[ 0.08170405  0.84312654  0.07516941]] [ 0.  0.  1.] 1\n",
      "[[ 0.04116886  0.67455757  0.28427365]] [ 0.  1.  0.] 1\n",
      "[[ 0.05741557  0.86244178  0.08014271]] [ 1.  0.  0.] 1\n",
      "[[ 0.74835724  0.25043547  0.0012073 ]] [ 0.  1.  0.] 0\n",
      "[[  9.05050256e-04   9.40898418e-01   5.81964999e-02]] [ 0.  1.  0.] 1\n",
      "[[ 0.96878457  0.00885505  0.02236035]] [ 1.  0.  0.] 0\n",
      "[[ 0.48668009  0.49746203  0.01585791]] [ 0.  1.  0.] 1\n",
      "[[ 0.65652359  0.3423076   0.0011688 ]] [ 1.  0.  0.] 0\n",
      "[[ 0.85896522  0.13857195  0.00246287]] [ 0.  1.  0.] 0\n",
      "[[ 0.07885246  0.18961017  0.7315374 ]] [ 0.  1.  0.] 2\n",
      "[[  2.96473740e-06   2.33376750e-06   9.99994755e-01]] [ 0.  0.  1.] 2\n",
      "[[  4.45385985e-02   6.46637112e-04   9.54814732e-01]] [ 0.  0.  1.] 2\n",
      "[[  9.66485641e-06   1.97210652e-03   9.98018265e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.00328388  0.99329776  0.00341839]] [ 0.  1.  0.] 1\n",
      "[[  1.16971312e-02   9.88252342e-01   5.05227581e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.81281888  0.15625495  0.03092611]] [ 1.  0.  0.] 0\n",
      "[[ 0.01693306  0.91927141  0.06379552]] [ 0.  0.  1.] 1\n",
      "[[ 0.01555546  0.9573229   0.02712165]] [ 0.  1.  0.] 1\n",
      "[[  9.89211202e-01   1.06936181e-02   9.51058319e-05]] [ 1.  0.  0.] 0\n",
      "[[ 0.97019392  0.01259969  0.01720636]] [ 1.  0.  0.] 0\n",
      "[[ 0.88486707  0.04776797  0.06736498]] [ 1.  0.  0.] 0\n",
      "[[ 0.00527995  0.02481764  0.9699024 ]] [ 1.  0.  0.] 2\n",
      "[[  1.18499484e-04   9.97554719e-01   2.32690806e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.04213833  0.95649439  0.00136722]] [ 0.  1.  0.] 1\n",
      "[[ 0.95317662  0.02609378  0.02072961]] [ 0.  0.  1.] 0\n",
      "[[ 0.00313939  0.00193205  0.9949286 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.03163512  0.66667408  0.30169073]] [ 0.  1.  0.] 1\n",
      "[[  8.52460289e-05   9.65951204e-01   3.39635648e-02]] [ 0.  1.  0.] 1\n",
      "[[  9.68248725e-01   3.10752615e-02   6.76038966e-04]] [ 0.  1.  0.] 0\n",
      "[[  2.45074183e-03   9.97455895e-01   9.33111733e-05]] [ 0.  1.  0.] 1\n",
      "[[  7.50653198e-05   9.99579012e-01   3.45945533e-04]] [ 1.  0.  0.] 1\n",
      "[[ 0.01230222  0.00136538  0.98633236]] [ 0.  1.  0.] 2\n",
      "[[ 0.06646556  0.9313491   0.00218533]] [ 1.  0.  0.] 1\n",
      "[[  9.82424676e-01   1.72776170e-02   2.97656457e-04]] [ 1.  0.  0.] 0\n",
      "[[  9.90992188e-01   6.80162862e-04   8.32767505e-03]] [ 0.  1.  0.] 0\n",
      "[[  3.27499991e-04   9.64198709e-01   3.54737900e-02]] [ 0.  1.  0.] 1\n",
      "[[ 0.00768374  0.98474902  0.00756727]] [ 0.  1.  0.] 1\n",
      "[[  2.65837205e-03   9.97259021e-01   8.26399555e-05]] [ 1.  0.  0.] 1\n",
      "[[ 0.07039342  0.28754514  0.64206141]] [ 1.  0.  0.] 2\n",
      "[[  3.51467123e-03   9.96076643e-01   4.08764026e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.26099524  0.67642432  0.06258044]] [ 0.  1.  0.] 1\n",
      "[[  9.51565919e-04   8.07706919e-03   9.90971327e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.48726907  0.26494747  0.24778341]] [ 0.  0.  1.] 0\n",
      "[[  2.17668060e-03   9.97820497e-01   2.87975672e-06]] [ 0.  1.  0.] 1\n",
      "[[ 0.21794635  0.75273657  0.02931713]] [ 0.  1.  0.] 1\n",
      "[[ 0.59180617  0.40711385  0.00108   ]] [ 0.  1.  0.] 0\n",
      "[[ 0.32890129  0.44885549  0.22224326]] [ 0.  1.  0.] 1\n",
      "[[  1.20127751e-02   1.35752634e-04   9.87851441e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.0293543   0.90525812  0.06538757]] [ 0.  1.  0.] 1\n",
      "[[ 0.00222868  0.95600832  0.041763  ]] [ 0.  1.  0.] 1\n",
      "[[  1.21554255e-01   8.78064632e-01   3.81160382e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.07412177  0.92370218  0.00217606]] [ 0.  1.  0.] 1\n",
      "[[ 0.01051681  0.23100303  0.75848013]] [ 0.  1.  0.] 2\n",
      "[[  1.72160240e-03   9.98227060e-01   5.14052954e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.00314757  0.99486911  0.00198326]] [ 0.  1.  0.] 1\n",
      "[[ 0.00142171  0.95467716  0.04390118]] [ 1.  0.  0.] 1\n",
      "[[ 0.18537781  0.81325698  0.00136523]] [ 1.  0.  0.] 1\n",
      "[[ 0.02612669  0.96229339  0.01157998]] [ 0.  1.  0.] 1\n",
      "[[ 0.10677096  0.87841898  0.01481009]] [ 0.  1.  0.] 1\n",
      "[[ 0.01958428  0.54206115  0.43835458]] [ 0.  0.  1.] 1\n",
      "[[ 0.45807913  0.31416595  0.22775492]] [ 0.  0.  1.] 0\n",
      "[[  2.52680348e-08   3.12675584e-05   9.99968648e-01]] [ 0.  0.  1.] 2\n",
      "[[  2.66632531e-03   9.96376336e-01   9.57294134e-04]] [ 0.  1.  0.] 1\n",
      "[[  3.41592520e-03   9.95981336e-01   6.02790504e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.44111526  0.55738229  0.00150245]] [ 0.  1.  0.] 1\n",
      "[[ 0.00421014  0.40189362  0.59389627]] [ 0.  0.  1.] 2\n",
      "[[ 0.13769504  0.02531996  0.83698493]] [ 0.  1.  0.] 2\n",
      "[[ 0.07743195  0.88903767  0.03353046]] [ 0.  1.  0.] 1\n",
      "[[ 0.03238458  0.14633949  0.82127589]] [ 0.  0.  1.] 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.79482561e-02   9.51893151e-01   1.58637107e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00235606  0.8554213   0.14222269]] [ 0.  1.  0.] 1\n",
      "[[ 0.00665202  0.61270821  0.3806397 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.08565588  0.80149704  0.11284718]] [ 0.  0.  1.] 1\n",
      "[[ 0.37064943  0.59496307  0.03438748]] [ 0.  1.  0.] 1\n",
      "[[ 0.00202822  0.8748318   0.12314006]] [ 0.  1.  0.] 1\n",
      "[[ 0.00480728  0.99358153  0.00161124]] [ 1.  0.  0.] 1\n",
      "[[ 0.09412164  0.18318184  0.72269654]] [ 0.  1.  0.] 2\n",
      "[[ 0.96949768  0.00822454  0.02227771]] [ 0.  0.  1.] 0\n",
      "[[  1.69902918e-07   1.54594469e-04   9.99845266e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.15963729  0.09701283  0.74334985]] [ 1.  0.  0.] 2\n",
      "[[ 0.00250759  0.98722082  0.01027158]] [ 0.  1.  0.] 1\n",
      "[[  2.24444229e-04   9.87146616e-01   1.26290303e-02]] [ 0.  1.  0.] 1\n",
      "[[  2.90478379e-01   7.09444165e-01   7.74760920e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.21452914  0.66760182  0.11786903]] [ 1.  0.  0.] 1\n",
      "[[ 0.02390044  0.95166391  0.02443564]] [ 0.  1.  0.] 1\n",
      "[[ 0.00608421  0.87926054  0.11465521]] [ 0.  1.  0.] 1\n",
      "[[ 0.96925777  0.02258971  0.00815253]] [ 0.  1.  0.] 0\n",
      "[[ 0.84318841  0.01032093  0.14649062]] [ 1.  0.  0.] 0\n",
      "[[ 0.01091957  0.0728291   0.9162513 ]] [ 0.  1.  0.] 2\n",
      "[[ 0.00126122  0.98982412  0.0089146 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.13774875  0.2440429   0.61820841]] [ 1.  0.  0.] 2\n",
      "[[ 0.11386104  0.8849709   0.00116811]] [ 0.  1.  0.] 1\n",
      "[[ 0.49119082  0.14317901  0.36563018]] [ 1.  0.  0.] 0\n",
      "[[ 0.00336914  0.99534661  0.00128434]] [ 0.  1.  0.] 1\n",
      "[[ 0.99065864  0.0069109   0.00243055]] [ 1.  0.  0.] 0\n",
      "[[ 0.04961345  0.93504983  0.01533673]] [ 0.  1.  0.] 1\n",
      "[[ 0.3808375   0.1961154   0.42304713]] [ 1.  0.  0.] 2\n",
      "[[ 0.00656279  0.00226943  0.99116778]] [ 0.  0.  1.] 2\n",
      "[[ 0.0083541   0.89979064  0.09185518]] [ 0.  0.  1.] 1\n",
      "[[ 0.12257124  0.09185823  0.7855705 ]] [ 0.  0.  1.] 2\n",
      "[[  4.85931896e-03   9.95085537e-01   5.51421945e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.01013655  0.98351729  0.00634611]] [ 0.  1.  0.] 1\n",
      "[[ 0.00374649  0.98736763  0.00888587]] [ 0.  1.  0.] 1\n",
      "[[  1.67366714e-04   9.99368608e-01   4.64072305e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00720874  0.98118901  0.01160218]] [ 0.  1.  0.] 1\n",
      "[[ 0.96031862  0.03459298  0.00508841]] [ 1.  0.  0.] 0\n",
      "[[ 0.0024164   0.99653047  0.00105316]] [ 0.  1.  0.] 1\n",
      "[[ 0.01293001  0.10774681  0.87932318]] [ 0.  0.  1.] 2\n",
      "[[ 0.19696632  0.80205154  0.00098217]] [ 0.  1.  0.] 1\n",
      "[[  1.79894250e-02   9.81828392e-01   1.82280637e-04]] [ 0.  1.  0.] 1\n",
      "[[  4.07814644e-02   9.58658397e-01   5.60049026e-04]] [ 0.  1.  0.] 1\n",
      "[[  2.68865648e-07   9.71028209e-01   2.89715957e-02]] [ 0.  1.  0.] 1\n",
      "[[  1.07644511e-04   9.90333378e-01   9.55899712e-03]] [ 0.  1.  0.] 1\n",
      "[[  6.30810022e-01   9.46531145e-06   3.69180530e-01]] [ 0.  1.  0.] 0\n",
      "[[ 0.06033826  0.87270379  0.06695794]] [ 0.  0.  1.] 1\n",
      "[[  2.50691563e-01   7.49177158e-01   1.31249893e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.47793123  0.03584088  0.48622778]] [ 0.  1.  0.] 2\n",
      "[[ 0.0033116   0.01951189  0.97717655]] [ 0.  0.  1.] 2\n",
      "[[  9.34903801e-05   6.56802297e-01   3.43104184e-01]] [ 0.  1.  0.] 1\n",
      "[[ 0.01633883  0.97906756  0.00459364]] [ 0.  1.  0.] 1\n",
      "[[ 0.05411892  0.82706273  0.11881831]] [ 0.  1.  0.] 1\n",
      "[[ 0.0079634   0.01252513  0.9795115 ]] [ 0.  1.  0.] 2\n",
      "[[ 0.06757343  0.8948217   0.03760482]] [ 0.  1.  0.] 1\n",
      "[[ 0.00946611  0.81970847  0.17082539]] [ 0.  0.  1.] 1\n",
      "[[  3.36368270e-02   9.65652287e-01   7.10881315e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.1085448   0.82409543  0.06735982]] [ 0.  1.  0.] 1\n",
      "[[ 0.0356821   0.95904553  0.00527244]] [ 1.  0.  0.] 1\n",
      "[[ 0.30839807  0.52144319  0.17015868]] [ 1.  0.  0.] 1\n",
      "[[ 0.4229826   0.21529318  0.36172417]] [ 1.  0.  0.] 0\n",
      "[[ 0.86159581  0.13077718  0.00762696]] [ 0.  1.  0.] 0\n",
      "[[  8.70027179e-06   1.99627061e-03   9.97995019e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.02774531  0.9695313   0.0027234 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.0395214   0.94215816  0.01832044]] [ 0.  1.  0.] 1\n",
      "[[  1.56667009e-01   8.43319416e-01   1.35853643e-05]] [ 0.  1.  0.] 1\n",
      "[[  1.53561874e-08   9.91051729e-06   9.99990106e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.04198997  0.92842454  0.02958547]] [ 0.  1.  0.] 1\n",
      "[[ 0.23381957  0.74501276  0.02116769]] [ 0.  1.  0.] 1\n",
      "[[ 0.00663365  0.9077068   0.08565951]] [ 0.  1.  0.] 1\n",
      "[[ 0.04345436  0.70110607  0.25543952]] [ 0.  0.  1.] 1\n",
      "[[ 0.07585159  0.91514707  0.00900138]] [ 0.  1.  0.] 1\n",
      "[[ 0.02275225  0.97334564  0.00390215]] [ 0.  1.  0.] 1\n",
      "[[  3.99547949e-04   9.94028330e-01   5.57211833e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.15911052  0.83932579  0.00156362]] [ 0.  1.  0.] 1\n",
      "[[ 0.0051857   0.99356538  0.00124899]] [ 0.  1.  0.] 1\n",
      "[[ 0.80184287  0.17251742  0.02563968]] [ 1.  0.  0.] 0\n",
      "[[ 0.0632036   0.83902365  0.09777273]] [ 0.  1.  0.] 1\n",
      "[[  8.74803126e-01   1.24847494e-01   3.49396985e-04]] [ 1.  0.  0.] 0\n",
      "[[  9.65624392e-01   1.30962744e-05   3.43624465e-02]] [ 0.  1.  0.] 0\n",
      "[[ 0.00398285  0.99497664  0.0010406 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.77153534  0.21480535  0.01365937]] [ 1.  0.  0.] 0\n",
      "[[  3.05493504e-01   6.94374800e-01   1.31724431e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00501825  0.98367047  0.01131128]] [ 0.  1.  0.] 1\n",
      "[[  5.58560848e-01   4.41276222e-01   1.62911514e-04]] [ 0.  1.  0.] 0\n",
      "[[ 0.39072451  0.58758324  0.0216923 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.00196158  0.97150022  0.02653819]] [ 0.  1.  0.] 1\n",
      "[[  2.21371563e-04   9.99332249e-01   4.46426711e-04]] [ 0.  1.  0.] 1\n",
      "[[  1.19157564e-02   9.88030970e-01   5.33086022e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.08793542  0.90251255  0.00955195]] [ 0.  1.  0.] 1\n",
      "[[ 0.01330944  0.33617812  0.65051246]] [ 0.  0.  1.] 2\n",
      "[[ 0.05622179  0.93162185  0.01215642]] [ 0.  1.  0.] 1\n",
      "[[  4.71497506e-01   5.28487563e-01   1.49163288e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.01143919  0.95859903  0.02996185]] [ 0.  1.  0.] 1\n",
      "[[ 0.22559105  0.654477    0.11993193]] [ 0.  1.  0.] 1\n",
      "[[ 0.0469184   0.87799597  0.07508558]] [ 1.  0.  0.] 1\n",
      "[[ 0.15650757  0.49573192  0.3477605 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.15973671  0.77511322  0.06515007]] [ 0.  1.  0.] 1\n",
      "[[  2.43582006e-04   3.58834833e-01   6.40921652e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.01645934  0.84101152  0.14252916]] [ 0.  1.  0.] 1\n",
      "[[  1.40372197e-06   8.07227480e-05   9.99917865e-01]] [ 0.  0.  1.] 2\n",
      "[[  6.77399163e-04   8.87371838e-01   1.11950710e-01]] [ 0.  1.  0.] 1\n",
      "[[  6.46062486e-04   9.99341905e-01   1.19964297e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.1623037   0.83493966  0.00275664]] [ 0.  1.  0.] 1\n",
      "[[ 0.01962875  0.97652197  0.00384927]] [ 0.  1.  0.] 1\n",
      "[[ 0.00476235  0.91028762  0.08495004]] [ 0.  1.  0.] 1\n",
      "[[ 0.43434575  0.56494713  0.00070714]] [ 1.  0.  0.] 1\n",
      "[[ 0.34496537  0.64918947  0.00584524]] [ 1.  0.  0.] 1\n",
      "[[ 0.01855993  0.36034429  0.62109578]] [ 1.  0.  0.] 2\n",
      "[[ 0.88939404  0.10123762  0.00936841]] [ 0.  1.  0.] 0\n",
      "[[ 0.02627704  0.92092651  0.05279646]] [ 1.  0.  0.] 1\n",
      "[[  2.31582955e-01   7.67831445e-01   5.85556671e-04]] [ 1.  0.  0.] 1\n",
      "[[  8.46413672e-01   1.52808696e-01   7.77679612e-04]] [ 0.  1.  0.] 0\n",
      "[[  8.93472910e-01   1.05662718e-01   8.64430214e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.39958113  0.58688492  0.01353393]] [ 0.  1.  0.] 1\n",
      "[[  9.94593084e-01   5.29868109e-03   1.08205306e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.00747312  0.97927618  0.01325064]] [ 0.  1.  0.] 1\n",
      "[[ 0.19511102  0.8020252   0.00286375]] [ 0.  1.  0.] 1\n",
      "[[  4.63659904e-04   1.96886454e-02   9.79847670e-01]] [ 0.  1.  0.] 2\n",
      "[[  2.50887359e-04   9.31782424e-01   6.79666251e-02]] [ 0.  1.  0.] 1\n",
      "[[ 0.27249178  0.67662817  0.0508801 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.50747424  0.08876327  0.40376246]] [ 1.  0.  0.] 0\n",
      "[[ 0.03953952  0.85742158  0.10303886]] [ 1.  0.  0.] 1\n",
      "[[ 0.02251599  0.19842385  0.77906013]] [ 0.  1.  0.] 2\n",
      "[[ 0.04109176  0.8335948   0.12531337]] [ 0.  1.  0.] 1\n",
      "[[  2.20259000e-02   9.77967262e-01   6.84526231e-06]] [ 0.  1.  0.] 1\n",
      "[[  5.91912365e-04   9.97974455e-01   1.43367588e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.0992294   0.68820208  0.21256843]] [ 0.  1.  0.] 1\n",
      "[[ 0.618613    0.21431662  0.16707039]] [ 0.  1.  0.] 0\n",
      "[[  2.31066160e-03   9.97646272e-01   4.30632681e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.72356743  0.26540354  0.01102907]] [ 1.  0.  0.] 0\n",
      "[[ 0.01345248  0.93886727  0.04768036]] [ 0.  1.  0.] 1\n",
      "[[ 0.03369836  0.95091987  0.01538185]] [ 0.  1.  0.] 1\n",
      "[[ 0.05530064  0.10915413  0.8355453 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.01169574  0.7081607   0.28014365]] [ 0.  1.  0.] 1\n",
      "[[ 0.1132372   0.48137128  0.40539148]] [ 0.  1.  0.] 1\n",
      "[[ 0.00501956  0.12360796  0.87137252]] [ 0.  1.  0.] 2\n",
      "[[ 0.14513706  0.29236612  0.56249678]] [ 1.  0.  0.] 2\n",
      "[[ 0.40202442  0.39863208  0.19934349]] [ 0.  1.  0.] 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00323828  0.0784641   0.91829759]] [ 0.  0.  1.] 2\n",
      "[[ 0.09240052  0.80433351  0.10326595]] [ 0.  1.  0.] 1\n",
      "[[ 0.00306314  0.97615427  0.02078265]] [ 0.  1.  0.] 1\n",
      "[[  9.40704167e-01   5.91696948e-02   1.26188301e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.08396017  0.90723592  0.00880393]] [ 0.  1.  0.] 1\n",
      "[[ 0.18886252  0.80932796  0.00180957]] [ 0.  1.  0.] 1\n",
      "[[ 0.36287719  0.63278127  0.00434149]] [ 0.  1.  0.] 1\n",
      "[[ 0.95078957  0.04601562  0.00319477]] [ 1.  0.  0.] 0\n",
      "[[ 0.02346401  0.96850944  0.0080266 ]] [ 1.  0.  0.] 1\n",
      "[[ 0.00639732  0.83824241  0.15536031]] [ 0.  1.  0.] 1\n",
      "[[ 0.00123931  0.99705887  0.00170178]] [ 0.  1.  0.] 1\n",
      "[[ 0.0146377   0.95150048  0.03386175]] [ 0.  1.  0.] 1\n",
      "[[ 0.32794765  0.37983403  0.2922183 ]] [ 0.  1.  0.] 1\n",
      "[[  4.91953362e-03   9.95070100e-01   1.04480278e-05]] [ 1.  0.  0.] 1\n",
      "[[ 0.11147033  0.88027686  0.0082528 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.48936021  0.00162008  0.50901973]] [ 0.  1.  0.] 2\n",
      "[[  2.52771206e-05   9.99096751e-01   8.78031540e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.03604448  0.94606042  0.01789516]] [ 0.  1.  0.] 1\n",
      "[[ 0.11569884  0.79811382  0.08618737]] [ 0.  0.  1.] 1\n",
      "[[ 0.00078072  0.68826336  0.31095597]] [ 1.  0.  0.] 1\n",
      "[[ 0.95229352  0.03078933  0.01691714]] [ 0.  1.  0.] 0\n",
      "[[  3.53805925e-04   2.87762936e-02   9.70869899e-01]] [ 0.  1.  0.] 2\n",
      "[[ 0.48654309  0.15363976  0.35981721]] [ 0.  1.  0.] 0\n",
      "[[  2.32267616e-04   9.75968242e-01   2.37995982e-02]] [ 0.  0.  1.] 1\n",
      "[[ 0.00131796  0.92238295  0.07629915]] [ 0.  1.  0.] 1\n",
      "[[  8.34345445e-03   9.91516352e-01   1.40183634e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00609968  0.19917712  0.79472321]] [ 0.  0.  1.] 2\n",
      "[[ 0.00077744  0.33850721  0.66071534]] [ 0.  1.  0.] 2\n",
      "[[ 0.02267819  0.12419211  0.85312974]] [ 1.  0.  0.] 2\n",
      "[[  6.33170009e-02   9.36000288e-01   6.82632148e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.0349961   0.80515957  0.15984435]] [ 0.  1.  0.] 1\n",
      "[[  3.24008070e-05   7.27658771e-05   9.99894857e-01]] [ 0.  0.  1.] 2\n",
      "[[  1.06658401e-04   8.16653715e-04   9.99076724e-01]] [ 0.  0.  1.] 2\n",
      "[[  9.32900846e-01   6.70905933e-02   8.60887212e-06]] [ 0.  1.  0.] 0\n",
      "[[  3.40975930e-07   8.49163462e-06   9.99991179e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.00678231  0.99207181  0.00114583]] [ 0.  1.  0.] 1\n",
      "[[  1.93205476e-02   9.80126739e-01   5.52681799e-04]] [ 0.  1.  0.] 1\n",
      "[[  1.49369672e-01   8.50556612e-01   7.37461232e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.00288377  0.79921687  0.19789937]] [ 0.  1.  0.] 1\n",
      "[[  1.67711079e-02   9.82757211e-01   4.71648702e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.40107337  0.02440587  0.57452077]] [ 0.  1.  0.] 2\n",
      "[[ 0.01167298  0.97774649  0.01058052]] [ 1.  0.  0.] 1\n",
      "[[ 0.01363817  0.66427112  0.32209072]] [ 0.  1.  0.] 1\n",
      "[[ 0.01132603  0.98421097  0.00446295]] [ 0.  1.  0.] 1\n",
      "[[ 0.01476082  0.71738696  0.26785225]] [ 0.  1.  0.] 1\n",
      "[[  2.04682767e-01   7.94905722e-01   4.11547517e-04]] [ 1.  0.  0.] 1\n",
      "[[ 0.17088027  0.82753277  0.00158696]] [ 0.  1.  0.] 1\n",
      "[[ 0.49165794  0.17675407  0.33158803]] [ 1.  0.  0.] 0\n",
      "[[ 0.37141293  0.45621175  0.17237538]] [ 1.  0.  0.] 1\n",
      "[[ 0.02342536  0.22045964  0.75611496]] [ 0.  0.  1.] 2\n",
      "[[ 0.01474699  0.0400132   0.94523978]] [ 0.  0.  1.] 2\n",
      "[[  1.29162538e-04   6.12305067e-02   9.38640356e-01]] [ 0.  0.  1.] 2\n",
      "[[  3.56393707e-06   6.28216753e-07   9.99995828e-01]] [ 0.  0.  1.] 2\n",
      "[[  3.94623280e-02   9.60524261e-01   1.34018719e-05]] [ 1.  0.  0.] 1\n",
      "[[ 0.01062729  0.5558607   0.433512  ]] [ 0.  1.  0.] 1\n",
      "[[ 0.00268165  0.99520063  0.00211765]] [ 0.  1.  0.] 1\n",
      "[[ 0.05673651  0.82252979  0.12073364]] [ 0.  1.  0.] 1\n",
      "[[  6.88233506e-03   9.92449999e-01   6.67734712e-04]] [ 0.  1.  0.] 1\n",
      "[[  6.98896311e-03   9.92764294e-01   2.46811542e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00229231  0.55875444  0.43895331]] [ 0.  1.  0.] 1\n",
      "[[ 0.04357288  0.79808122  0.15834594]] [ 0.  1.  0.] 1\n",
      "[[ 0.00114832  0.00879438  0.99005729]] [ 1.  0.  0.] 2\n",
      "[[ 0.00085092  0.4348838   0.56426525]] [ 0.  0.  1.] 2\n",
      "[[  2.38527355e-04   2.79825121e-01   7.19936371e-01]] [ 0.  1.  0.] 2\n",
      "[[ 0.01271334  0.98469168  0.00259504]] [ 0.  1.  0.] 1\n",
      "[[  9.35009003e-01   6.49485514e-02   4.24400314e-05]] [ 0.  1.  0.] 0\n",
      "[[  5.22855530e-03   9.94691074e-01   8.04349183e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.9046796   0.09257352  0.00274699]] [ 1.  0.  0.] 0\n",
      "[[ 0.63717532  0.33929822  0.02352643]] [ 1.  0.  0.] 0\n",
      "[[ 0.47674385  0.51912063  0.0041356 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.08498012  0.91201013  0.00300986]] [ 0.  1.  0.] 1\n",
      "[[  7.27530627e-04   2.55520195e-01   7.43752301e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.00160382  0.65629071  0.34210551]] [ 0.  1.  0.] 1\n",
      "[[ 0.17680298  0.82019323  0.00300382]] [ 0.  1.  0.] 1\n",
      "[[ 0.14461309  0.75052035  0.10486654]] [ 0.  1.  0.] 1\n",
      "[[  7.57045997e-03   9.91991937e-01   4.37695649e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.02339519  0.88491815  0.09168676]] [ 0.  1.  0.] 1\n",
      "[[  4.28030431e-01   5.71550786e-01   4.18793381e-04]] [ 1.  0.  0.] 1\n",
      "[[  7.60674084e-08   1.37388824e-05   9.99986172e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.04518569  0.63464856  0.32016569]] [ 0.  1.  0.] 1\n",
      "[[  5.52576443e-04   9.95505571e-01   3.94181628e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.2149954   0.78230721  0.00269738]] [ 0.  1.  0.] 1\n",
      "[[  2.15910695e-04   8.69775474e-01   1.30008623e-01]] [ 0.  0.  1.] 1\n",
      "[[ 0.00282399  0.10334948  0.89382648]] [ 0.  1.  0.] 2\n",
      "[[ 0.99041861  0.00660111  0.0029802 ]] [ 0.  1.  0.] 0\n",
      "[[  5.25430078e-04   6.37164041e-02   9.35758173e-01]] [ 0.  1.  0.] 2\n",
      "[[ 0.09552132  0.1144633   0.7900154 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.00786977  0.97352988  0.01860037]] [ 0.  1.  0.] 1\n",
      "[[ 0.04367039  0.73594791  0.22038171]] [ 0.  1.  0.] 1\n",
      "[[  1.94861004e-05   1.60225883e-01   8.39754641e-01]] [ 0.  1.  0.] 2\n",
      "[[  2.75225175e-05   9.99924064e-01   4.84487573e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.02020887  0.96365887  0.01613225]] [ 0.  1.  0.] 1\n",
      "[[ 0.01200963  0.78323364  0.20475663]] [ 0.  1.  0.] 1\n",
      "[[ 0.00133542  0.99716836  0.00149621]] [ 0.  1.  0.] 1\n",
      "[[ 0.01634564  0.10326274  0.8803916 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.15473028  0.82536566  0.01990407]] [ 0.  0.  1.] 1\n",
      "[[  8.97044607e-04   9.98341203e-01   7.61795498e-04]] [ 0.  1.  0.] 1\n",
      "[[  4.59647700e-02   9.53156471e-01   8.78832303e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.08056191  0.0962461   0.823192  ]] [ 0.  1.  0.] 2\n",
      "[[ 0.99752408  0.00114939  0.00132653]] [ 1.  0.  0.] 0\n",
      "[[  3.41935009e-02   9.65780020e-01   2.64575501e-05]] [ 1.  0.  0.] 1\n",
      "[[ 0.43386516  0.47116381  0.09497103]] [ 0.  1.  0.] 1\n",
      "[[ 0.00430501  0.49058515  0.50510979]] [ 1.  0.  0.] 2\n",
      "[[ 0.87553066  0.10154401  0.02292543]] [ 0.  1.  0.] 0\n",
      "[[ 0.46003115  0.52473241  0.01523648]] [ 0.  1.  0.] 1\n",
      "[[ 0.17619047  0.75187951  0.07193001]] [ 1.  0.  0.] 1\n",
      "[[ 0.06615938  0.91275018  0.02109045]] [ 0.  1.  0.] 1\n",
      "[[  6.29642629e-04   9.98642743e-01   7.27637031e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.88236529  0.10158495  0.01604968]] [ 0.  0.  1.] 0\n",
      "[[ 0.02970959  0.00215935  0.96813107]] [ 0.  0.  1.] 2\n",
      "[[  5.32115763e-03   9.94610667e-01   6.81758320e-05]] [ 0.  1.  0.] 1\n",
      "[[  7.71165133e-01   6.35998776e-06   2.28828475e-01]] [ 0.  1.  0.] 0\n",
      "[[  6.69169053e-03   9.93302107e-01   6.22882226e-06]] [ 0.  1.  0.] 1\n",
      "[[  2.09533516e-03   9.97057915e-01   8.46784911e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00344129  0.02587485  0.97068381]] [ 0.  0.  1.] 2\n",
      "[[  1.66190080e-02   9.83240306e-01   1.40696589e-04]] [ 0.  1.  0.] 1\n",
      "[[  9.98284400e-01   1.39432412e-03   3.21179978e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.64021033  0.35554332  0.00424643]] [ 0.  1.  0.] 0\n",
      "[[ 0.04032731  0.17735691  0.78231579]] [ 1.  0.  0.] 2\n",
      "[[  7.41717964e-02   9.25740659e-01   8.76299673e-05]] [ 0.  1.  0.] 1\n",
      "[[  3.54660035e-04   1.47456378e-01   8.52188945e-01]] [ 1.  0.  0.] 2\n",
      "[[ 0.0151717   0.12438515  0.86044312]] [ 0.  0.  1.] 2\n",
      "[[  1.28977075e-02   9.87079799e-01   2.24316809e-05]] [ 0.  1.  0.] 1\n",
      "[[  1.93979386e-02   9.79685009e-01   9.17063036e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00636764  0.91255015  0.08108222]] [ 0.  1.  0.] 1\n",
      "[[  3.39775463e-04   9.99552906e-01   1.07249041e-04]] [ 0.  0.  1.] 1\n",
      "[[  5.11631370e-01   4.88359094e-01   9.51038874e-06]] [ 0.  1.  0.] 0\n",
      "[[ 0.02252876  0.69318163  0.28428969]] [ 1.  0.  0.] 1\n",
      "[[  1.27459448e-02   9.87071455e-01   1.82581047e-04]] [ 0.  1.  0.] 1\n",
      "[[  1.18945877e-06   2.10981554e-04   9.99787867e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.03602055  0.69238818  0.27159131]] [ 0.  1.  0.] 1\n",
      "[[ 0.00273469  0.9673785   0.02988675]] [ 0.  1.  0.] 1\n",
      "[[ 0.93262786  0.05675178  0.01062033]] [ 0.  1.  0.] 0\n",
      "[[  4.83084768e-02   9.51630116e-01   6.13708762e-05]] [ 0.  1.  0.] 1\n",
      "[[  7.80020375e-03   9.92127895e-01   7.19451709e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.85363442  0.14343445  0.00293113]] [ 1.  0.  0.] 0\n",
      "[[ 0.01670199  0.28400984  0.69928819]] [ 0.  0.  1.] 2\n",
      "[[  3.76087934e-04   9.99480665e-01   1.43390062e-04]] [ 0.  1.  0.] 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22119598  0.72374183  0.05506218]] [ 0.  0.  1.] 1\n",
      "[[  8.91092539e-01   1.08782075e-01   1.25338629e-04]] [ 0.  1.  0.] 0\n",
      "[[ 0.00384018  0.87825376  0.11790609]] [ 0.  0.  1.] 1\n",
      "[[ 0.16755289  0.80312747  0.02931955]] [ 0.  1.  0.] 1\n",
      "[[  2.48119272e-02   9.75119531e-01   6.86262210e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.01613726  0.01076654  0.97309619]] [ 0.  0.  1.] 2\n",
      "[[ 0.42436886  0.57432359  0.00130757]] [ 0.  1.  0.] 1\n",
      "[[  6.15930676e-01   3.83816928e-01   2.52330035e-04]] [ 0.  1.  0.] 0\n",
      "[[ 0.02451931  0.95417798  0.02130276]] [ 0.  1.  0.] 1\n",
      "[[  9.91807759e-01   8.11224431e-03   7.99643167e-05]] [ 1.  0.  0.] 0\n",
      "[[ 0.52010983  0.47597045  0.00391972]] [ 1.  0.  0.] 0\n",
      "[[  4.49802391e-02   9.54907119e-01   1.12540867e-04]] [ 0.  1.  0.] 1\n",
      "[[  1.38932106e-03   9.98604596e-01   6.06202866e-06]] [ 0.  1.  0.] 1\n",
      "[[  5.24207167e-02   9.46990788e-01   5.88515133e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.0449796   0.84194487  0.11307556]] [ 0.  1.  0.] 1\n",
      "[[  1.12202624e-03   9.98155534e-01   7.22407247e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.01637354  0.35382453  0.62980193]] [ 0.  1.  0.] 2\n",
      "[[  1.46455492e-03   9.98443186e-01   9.22776744e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.45125493  0.02433791  0.52440715]] [ 1.  0.  0.] 2\n",
      "[[  2.53396684e-05   9.95831668e-01   4.14303504e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.53769553  0.27926242  0.18304209]] [ 0.  1.  0.] 0\n",
      "[[  1.69458904e-03   9.98290360e-01   1.50399237e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.86384547  0.122221    0.01393358]] [ 1.  0.  0.] 0\n",
      "[[ 0.49071598  0.40561873  0.10366528]] [ 0.  1.  0.] 0\n",
      "[[  1.56635861e-03   8.42245645e-04   9.97591376e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.13828027  0.84972727  0.01199246]] [ 1.  0.  0.] 1\n",
      "[[  2.87611299e-04   9.85543370e-01   1.41689954e-02]] [ 0.  1.  0.] 1\n",
      "[[  2.12506638e-04   2.92689051e-03   9.96860623e-01]] [ 0.  1.  0.] 2\n",
      "[[  3.41693684e-02   9.65575039e-01   2.55588384e-04]] [ 0.  1.  0.] 1\n",
      "[[  5.92634454e-03   2.87199306e-04   9.93786454e-01]] [ 1.  0.  0.] 2\n",
      "[[  7.56040692e-01   2.43681982e-01   2.77340499e-04]] [ 0.  1.  0.] 0\n",
      "[[  3.90270166e-02   9.60779727e-01   1.93170243e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.00710942  0.11581511  0.87707549]] [ 0.  1.  0.] 2\n",
      "[[ 0.48619026  0.48373663  0.03007311]] [ 0.  1.  0.] 0\n",
      "[[ 0.0038215   0.99189514  0.00428331]] [ 0.  1.  0.] 1\n",
      "[[ 0.00109959  0.99617529  0.00272514]] [ 0.  1.  0.] 1\n",
      "[[ 0.00718648  0.001545    0.99126852]] [ 0.  0.  1.] 2\n",
      "[[ 0.11387277  0.88424385  0.00188337]] [ 0.  1.  0.] 1\n",
      "[[ 0.25192127  0.5054298   0.24264891]] [ 1.  0.  0.] 1\n",
      "[[ 0.84059966  0.11630699  0.04309333]] [ 0.  1.  0.] 0\n",
      "[[ 0.65994203  0.31598726  0.02407065]] [ 0.  1.  0.] 0\n",
      "[[ 0.09561541  0.67808497  0.22629963]] [ 0.  1.  0.] 1\n",
      "[[ 0.06526011  0.80427325  0.13046658]] [ 0.  1.  0.] 1\n",
      "[[ 0.00111859  0.99509335  0.00378807]] [ 0.  1.  0.] 1\n",
      "[[ 0.82606971  0.13286135  0.04106899]] [ 1.  0.  0.] 0\n",
      "[[  9.99058187e-01   4.69463965e-04   4.72391519e-04]] [ 1.  0.  0.] 0\n",
      "[[ 0.25999156  0.71740258  0.02260589]] [ 0.  1.  0.] 1\n",
      "[[ 0.00681583  0.86857265  0.12461143]] [ 0.  1.  0.] 1\n",
      "[[  8.84830661e-04   9.98593271e-01   5.21826849e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.82193494  0.17060068  0.0074644 ]] [ 1.  0.  0.] 0\n",
      "[[ 0.15894967  0.8327983   0.00825199]] [ 0.  1.  0.] 1\n",
      "[[ 0.9499377   0.00528269  0.04477956]] [ 0.  1.  0.] 0\n",
      "[[ 0.01087188  0.1945886   0.79453945]] [ 1.  0.  0.] 2\n",
      "[[  1.57353461e-05   9.80603755e-01   1.93805266e-02]] [ 0.  0.  1.] 1\n",
      "[[ 0.0029829   0.99283183  0.00418526]] [ 0.  1.  0.] 1\n",
      "[[ 0.79296458  0.01185517  0.19518027]] [ 0.  0.  1.] 0\n",
      "[[ 0.01062345  0.9790957   0.01028086]] [ 0.  1.  0.] 1\n",
      "[[ 0.03737208  0.86943501  0.09319284]] [ 0.  1.  0.] 1\n",
      "[[ 0.33096626  0.64943939  0.01959435]] [ 0.  1.  0.] 1\n",
      "[[  1.02117453e-02   9.89728034e-01   6.02755572e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.09798234  0.90011519  0.00190242]] [ 0.  1.  0.] 1\n",
      "[[ 0.8621816   0.06293985  0.07487856]] [ 0.  1.  0.] 0\n",
      "[[ 0.05640965  0.92935622  0.01423412]] [ 0.  1.  0.] 1\n",
      "[[ 0.03907548  0.95788401  0.00304046]] [ 0.  1.  0.] 1\n",
      "[[ 0.89867777  0.05627312  0.04504912]] [ 0.  0.  1.] 0\n",
      "[[ 0.25581077  0.16700317  0.57718611]] [ 0.  1.  0.] 2\n",
      "[[  2.56180821e-04   8.81993473e-01   1.17750339e-01]] [ 0.  1.  0.] 1\n",
      "[[ 0.01255766  0.98518938  0.00225296]] [ 0.  1.  0.] 1\n",
      "[[ 0.00343484  0.2395409   0.75702429]] [ 0.  1.  0.] 2\n",
      "[[  1.14119910e-04   7.63047710e-02   9.23581064e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.16879942  0.03446617  0.79673445]] [ 1.  0.  0.] 2\n",
      "[[  1.13704450e-01   8.85411084e-01   8.84443463e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.02933088  0.96894217  0.00172699]] [ 0.  1.  0.] 1\n",
      "[[ 0.01782596  0.02961945  0.95255458]] [ 0.  0.  1.] 2\n",
      "[[ 0.05488763  0.94311428  0.00199801]] [ 0.  1.  0.] 1\n",
      "[[  3.28314081e-02   9.67155278e-01   1.32124542e-05]] [ 0.  1.  0.] 1\n",
      "[[  7.64376745e-02   9.23213720e-01   3.48527159e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.04553692  0.16642934  0.78803372]] [ 1.  0.  0.] 2\n",
      "[[ 0.13626443  0.01227828  0.85145724]] [ 1.  0.  0.] 2\n",
      "[[ 0.4084405   0.58670139  0.00485814]] [ 0.  1.  0.] 1\n",
      "[[  7.77050809e-05   9.95377183e-01   4.54511959e-03]] [ 0.  1.  0.] 1\n",
      "[[ 0.01032836  0.79227209  0.19739953]] [ 0.  1.  0.] 1\n",
      "[[ 0.6704632   0.19832295  0.13121381]] [ 0.  1.  0.] 0\n",
      "[[ 0.91373062  0.04685565  0.03941367]] [ 1.  0.  0.] 0\n",
      "[[ 0.03305139  0.00690183  0.96004671]] [ 0.  0.  1.] 2\n",
      "[[ 0.00363484  0.28542489  0.71094024]] [ 0.  1.  0.] 2\n",
      "[[ 0.35625499  0.57705659  0.0666884 ]] [ 0.  1.  0.] 1\n",
      "[[  2.56317198e-01   7.43663549e-01   1.92774751e-05]] [ 0.  1.  0.] 1\n",
      "[[  1.25739319e-07   1.43858371e-03   9.98561323e-01]] [ 0.  0.  1.] 2\n",
      "[[  6.99138347e-09   3.47220812e-08   1.00000000e+00]] [ 0.  0.  1.] 2\n",
      "[[ 0.46047774  0.53484958  0.00467272]] [ 0.  1.  0.] 1\n",
      "[[ 0.08960781  0.54438818  0.36600408]] [ 0.  1.  0.] 1\n",
      "[[ 0.00323544  0.00833579  0.98842877]] [ 0.  0.  1.] 2\n",
      "[[  2.70066321e-01   7.29578733e-01   3.54948075e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.6330061   0.02050338  0.34649053]] [ 1.  0.  0.] 0\n",
      "[[ 0.78289902  0.10547733  0.1116236 ]] [ 1.  0.  0.] 0\n",
      "[[  6.70473184e-03   9.93224025e-01   7.12798355e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.00867323  0.51211679  0.47920993]] [ 0.  1.  0.] 1\n",
      "[[ 0.00971618  0.31613514  0.67414868]] [ 1.  0.  0.] 2\n",
      "[[ 0.77290082  0.14280094  0.08429818]] [ 0.  1.  0.] 0\n",
      "[[ 0.77920485  0.03822004  0.18257502]] [ 1.  0.  0.] 0\n",
      "[[ 0.62776697  0.36526957  0.00696353]] [ 1.  0.  0.] 0\n",
      "[[ 0.8300429   0.14098115  0.02897596]] [ 1.  0.  0.] 0\n",
      "[[ 0.74309105  0.16868585  0.08822308]] [ 1.  0.  0.] 0\n",
      "[[ 0.04094262  0.37924555  0.57981181]] [ 1.  0.  0.] 2\n",
      "[[  2.33164474e-01   7.66814649e-01   2.08560214e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.00110306  0.88231325  0.11658373]] [ 0.  1.  0.] 1\n",
      "[[  1.03337049e-01   8.96347523e-01   3.15392128e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.30659693  0.42534438  0.26805866]] [ 0.  1.  0.] 1\n",
      "[[ 0.00572592  0.96762484  0.0266492 ]] [ 1.  0.  0.] 1\n",
      "[[ 0.01628548  0.97570783  0.00800662]] [ 0.  1.  0.] 1\n",
      "[[ 0.05380545  0.93197536  0.0142192 ]] [ 0.  1.  0.] 1\n",
      "[[ 0.75687051  0.21592583  0.02720368]] [ 1.  0.  0.] 0\n",
      "[[ 0.01480126  0.2104522   0.77474648]] [ 0.  0.  1.] 2\n",
      "[[ 0.04299886  0.95150113  0.0055    ]] [ 0.  1.  0.] 1\n",
      "[[ 0.00759723  0.01012571  0.9822771 ]] [ 0.  0.  1.] 2\n",
      "[[  7.81511699e-06   9.80995357e-01   1.89968441e-02]] [ 0.  1.  0.] 1\n",
      "[[  3.18581983e-02   9.67684150e-01   4.57656861e-04]] [ 0.  1.  0.] 1\n",
      "[[  9.90484238e-01   6.86978012e-07   9.51506570e-03]] [ 0.  1.  0.] 0\n",
      "[[  1.23343468e-02   9.87086177e-01   5.79384621e-04]] [ 0.  1.  0.] 1\n",
      "[[  9.24616307e-02   9.07502174e-01   3.62329301e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.08137406  0.9075495   0.01107638]] [ 0.  1.  0.] 1\n",
      "[[  7.13181333e-04   9.99147296e-01   1.39528376e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.61168742  0.01824384  0.37006876]] [ 1.  0.  0.] 0\n",
      "[[  7.85888551e-05   5.69224581e-02   9.42998886e-01]] [ 0.  0.  1.] 2\n",
      "[[  1.01928841e-02   9.89798307e-01   8.80174684e-06]] [ 0.  1.  0.] 1\n",
      "[[ 0.48201996  0.47748682  0.04049321]] [ 0.  1.  0.] 0\n",
      "[[ 0.09446923  0.77270418  0.13282657]] [ 0.  1.  0.] 1\n",
      "[[  1.07369544e-02   9.89115894e-01   1.47095023e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.0901248   0.90335232  0.0065229 ]] [ 0.  1.  0.] 1\n",
      "[[  1.47534311e-01   8.51732790e-01   7.32829503e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.29430115  0.04862577  0.65707314]] [ 0.  1.  0.] 2\n",
      "[[ 0.47385812  0.17200033  0.35414153]] [ 1.  0.  0.] 0\n",
      "[[ 0.00374647  0.59073001  0.40552351]] [ 0.  1.  0.] 1\n",
      "[[ 0.03163039  0.95541078  0.01295883]] [ 0.  1.  0.] 1\n",
      "[[ 0.81070751  0.06940795  0.11988453]] [ 1.  0.  0.] 0\n",
      "[[ 0.00547467  0.17373078  0.82079452]] [ 0.  1.  0.] 2\n",
      "[[ 0.38465139  0.6101501   0.00519858]] [ 1.  0.  0.] 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36942524  0.2434724   0.38710237]] [ 1.  0.  0.] 2\n",
      "[[ 0.00198614  0.99361175  0.00440212]] [ 0.  1.  0.] 1\n",
      "[[ 0.03318641  0.84990162  0.11691194]] [ 0.  1.  0.] 1\n",
      "[[ 0.00585418  0.73257774  0.26156807]] [ 0.  1.  0.] 1\n",
      "[[ 0.00068797  0.65449834  0.34481367]] [ 1.  0.  0.] 1\n",
      "[[  4.18047217e-04   9.92296159e-01   7.28582311e-03]] [ 0.  1.  0.] 1\n",
      "[[  3.95028590e-04   9.85170066e-01   1.44348843e-02]] [ 0.  1.  0.] 1\n",
      "[[ 0.21991041  0.77823251  0.00185698]] [ 0.  0.  1.] 1\n",
      "[[ 0.02797969  0.963835    0.00818531]] [ 0.  1.  0.] 1\n",
      "[[ 0.63100278  0.00352629  0.36547089]] [ 1.  0.  0.] 0\n",
      "[[  1.20011078e-04   9.99602377e-01   2.77596060e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.8750183   0.10553446  0.01944723]] [ 0.  1.  0.] 0\n",
      "[[ 0.35920715  0.40105614  0.23973677]] [ 0.  1.  0.] 1\n",
      "[[  3.60816047e-02   9.63892698e-01   2.55903487e-05]] [ 0.  1.  0.] 1\n",
      "[[ 0.00228121  0.06386083  0.93385798]] [ 0.  0.  1.] 2\n",
      "[[ 0.04282435  0.01072935  0.9464463 ]] [ 1.  0.  0.] 2\n",
      "[[ 0.0315373   0.88155532  0.08690739]] [ 0.  0.  1.] 1\n",
      "[[ 0.01507779  0.98151463  0.00340757]] [ 0.  1.  0.] 1\n",
      "[[ 0.02946945  0.9253481   0.04518247]] [ 1.  0.  0.] 1\n",
      "[[ 0.11684674  0.84770823  0.03544505]] [ 0.  1.  0.] 1\n",
      "[[ 0.18295926  0.04113087  0.7759099 ]] [ 0.  1.  0.] 2\n",
      "[[ 0.00191322  0.12704156  0.87104523]] [ 0.  0.  1.] 2\n",
      "[[  8.05504169e-06   9.59129274e-01   4.08626720e-02]] [ 0.  1.  0.] 1\n",
      "[[ 0.00257739  0.85052609  0.1468965 ]] [ 0.  1.  0.] 1\n",
      "[[  4.72160551e-04   1.51842302e-02   9.84343648e-01]] [ 0.  0.  1.] 2\n",
      "[[ 0.00113006  0.2513358   0.7475341 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.00739096  0.18664651  0.80596256]] [ 0.  1.  0.] 2\n",
      "[[ 0.5230965   0.41661802  0.06028548]] [ 0.  1.  0.] 0\n",
      "[[ 0.00710942  0.11581511  0.87707549]] [ 0.  1.  0.] 2\n",
      "[[  1.36131616e-02   9.86178041e-01   2.08815269e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.03291978  0.96457821  0.00250199]] [ 0.  1.  0.] 1\n",
      "[[ 0.96311551  0.03551682  0.0013677 ]] [ 1.  0.  0.] 0\n",
      "[[ 0.6836884   0.27861217  0.03769938]] [ 0.  1.  0.] 0\n",
      "[[  9.64692445e-04   9.98039305e-01   9.96007817e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.97858799  0.00260591  0.01880617]] [ 1.  0.  0.] 0\n",
      "[[ 0.7033208   0.2927492   0.00392991]] [ 1.  0.  0.] 0\n",
      "[[ 0.0180077   0.15030855  0.8316837 ]] [ 0.  0.  1.] 2\n",
      "[[ 0.0038825   0.99101382  0.00510363]] [ 0.  1.  0.] 1\n",
      "[[  1.78267155e-02   9.82167006e-01   6.15961926e-06]] [ 1.  0.  0.] 1\n",
      "[[ 0.04120049  0.09991151  0.85888803]] [ 0.  0.  1.] 2\n",
      "[[ 0.01195078  0.98637646  0.00167275]] [ 0.  1.  0.] 1\n",
      "[[ 0.00372085  0.90854681  0.08773235]] [ 0.  1.  0.] 1\n",
      "[[ 0.04989578  0.94766593  0.00243824]] [ 0.  1.  0.] 1\n",
      "[[  3.88551056e-02   9.60871398e-01   2.73570156e-04]] [ 0.  1.  0.] 1\n",
      "[[ 0.94119072  0.00883568  0.04997368]] [ 1.  0.  0.] 0\n",
      "[[ 0.03171497  0.96451145  0.00377358]] [ 0.  1.  0.] 1\n",
      "[[ 0.6604178   0.31079614  0.02878598]] [ 1.  0.  0.] 0\n",
      "[[ 0.47163165  0.52611339  0.00225498]] [ 0.  1.  0.] 1\n",
      "[[ 0.40709662  0.58475888  0.00814441]] [ 0.  1.  0.] 1\n",
      "[[ 0.8394506   0.05893176  0.10161756]] [ 0.  0.  1.] 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_pred = pd.DataFrame(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "for ii in range(len(test_targets)):\n",
    "    probability = model.predict(np.expand_dims(test_tensors[ii], axis=0))\n",
    "    ground_truth = test_targets[ii]\n",
    "    prediction = np.argmax(probability)\n",
    "    print(probability, ground_truth, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:21<00:00, 27.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_pred = pd.DataFrame(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "for ii in tqdm(range(len(test_tensors))):\n",
    "    #path = test_files[ii]\n",
    "    prediction = np.argmax(model.predict(np.expand_dims(test_tensors[ii], axis=0)))    \n",
    "    y_pred.loc[ii] = [0, 0]\n",
    "   # print(prediction)\n",
    "    #print(prediction == 0)\n",
    "    if prediction == 0:\n",
    "        y_pred.loc[ii]['task_1'] = 1\n",
    "        #print(\"melanoma detected at row \",ii)\n",
    "    if prediction == 2:\n",
    "        y_pred.loc[ii]['task_2'] = 1\n",
    "        \n",
    "y_pred.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal testing vs. ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def plot_roc_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function plots the ROC curves and provides the scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize dictionaries and array\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = np.zeros(3)\n",
    "    \n",
    "    # prepare for figure\n",
    "    plt.figure()\n",
    "    colors = ['aqua', 'cornflowerblue']\n",
    "\n",
    "    # for both classification tasks (categories 1 and 2)\n",
    "    for i in range(2):\n",
    "        # obtain ROC curve\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:,i], y_pred[:,i])\n",
    "        # obtain ROC AUC\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        # plot ROC curve\n",
    "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n",
    "                 label='ROC curve for task {d} (area = {f:.2f})'.format(d=i+1, f=roc_auc[i]))\n",
    "    # get score for category 3\n",
    "    roc_auc[2] = np.average(roc_auc[:2])\n",
    "    \n",
    "    # format figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    # print scores\n",
    "    for i in range(3):\n",
    "        print('Category {d} Score: {f:.3f}'. format(d=i+1, f=roc_auc[i]))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, thresh, classes):\n",
    "    \"\"\"\n",
    "    This function plots the (normalized) confusion matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain class predictions from probabilities\n",
    "    y_pred = (y_pred>=thresh)*1\n",
    "    # obtain (unnormalized) confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # normalize confusion matrix\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd0lEUXwOHfJJBAQu9Ib0oLHQFB\nAUFEQZEmop+ADVGKgAqISldRqvQOgmABFLCCiHTpvfcSpIaaXvZ+f8wSAiRLKJt6n3NyTmZ3dt+7\ngd278859Z4yIoJRSSsXFI7EDUEoplbRpolBKKeWSJgqllFIuaaJQSinlkiYKpZRSLmmiUEop5ZIm\nCqWUUi5polApgjHmmDEmxBgTaIw5Y4yZYYzJcEufx4wxy4wx14wxV4wxvxhjSt/SJ5MxZqQx5oTz\nuQ472zkS9hUplXRoolApyXMikgGoAFQEPrp+hzGmBrAEWAg8BBQBtgNrjDFFnX28gL+BMkBDIBNQ\nAwgAHnVX0MaYNO56bqUeBE0UKsURkTPAYmzCuO4rYKaIfC0i10Tkooh8AqwD+jn7tAEKAk1FZI+I\nOETknIgMFJHfYzuWMaaMMeYvY8xFY8xZY0xv5+0zjDGDYvSrY4zxj9E+ZozpaYzZAQQ5f593y3N/\nbYwZ5fw9szFmqjHmtDHmlDFmkDHG03lfcWPMCuco6YIx5of7+gMqdQtNFCrFMcbkB54BDjnbPsBj\nwNxYuv8IPOX8vT7wp4gExvM4GYGlwJ/YUUpx7IgkvloDjYAswPfAs87nxJkEXgTmOPvOACKdx6gI\nNADedN43EDtaygrkB0bfRQxK3ZEmCpWSLDDGXANOAueAvs7bs2H/r5+O5TGngevzD9nj6BOXxsAZ\nERkmIqHOkcr6u3j8KBE5KSIhInIc2AI0dd73JBAsIuuMMbmBZ4GuIhIkIueAEcBLzr4RQCHgIWcc\nq+8iBqXuSBOFSkleEJGMQB2gJDcSwCXAAeSN5TF5gQvO3wPi6BOXAsDhe4rUOnlLew52lAHwMjdG\nE4WAtMBpY8xlY8xlYCKQy3l/D8AAG4wxu40xr99HTErdRhOFSnFEZAX2VM1QZzsI+BdoGUv3F7lx\numgp8LQxxjeehzoJFI3jviDAJ0Y7T2yh3tKeC9Rxnjpryo1EcRIIA3KISBbnTyYRKQN2TkZE3hKR\nh4C3gXHGmOLxfA1K3ZEmCpVSjQSeMsaUd7Z7AW2NMV2MMRmNMVmdk801gP7OPrOwH8rzjTEljTEe\nxpjsxpjexphnYznGr0BeY0xXY4y383mrOe/bhp1zyGaMyQN0vVPAInIeWA5MB46KyF7n7aexcxDD\nnOW7HsaYYsaY2gDGmJbO5AJ29CTYEZRSD4QmCpUiOT90ZwJ9nO3VwNNAM+w8xHHspHAtETno7BOG\nndDeB/wFXAU2YE9h3Tb3ICLXsBPhzwFngINAXefds7Dlt8ewH/LxrUSa44xhzi23twG8gD3YZDCP\nG6fJqgLrjTGBwCLgPRE5Es/jKXVHRjcuUkop5YqOKJRSSrmkiUIppZRLmiiUUkq5pIlCKaWUS8lu\nMbIcOXJI4cKFEzsMpZRKVjZv3nxBRHLey2OTXaIoXLgwmzZtSuwwlFIqWTHGHL/Xx+qpJ6WUUi5p\nolBKKeWSJgqllFIuaaJQSinlkiYKpZRSLmmiUEop5ZLbEoUxZpox5pwxZlcc9xtjzChjzCFjzA5j\nTCV3xaKUUureuXNEMQNo6OL+Z4ASzp/2wHg3xqKUUqnWD8eD7uvxbrvgTkRWGmMKu+jSBJgpdp3z\ndcaYLMaYvM5NWpRSSt2nAyEOmrXrxqXt2+7reRLzyux83LxnsL/zttsShTGmPXbUQcGCBRMkOKWU\nSq6CRRi4N5xT/waT3fth9h6ecF/Plywms0VkkohUEZEqOXPe01IlSimV4gkweO0O6nSdwoXlQXiH\nCYWb/4+fN++5r+dNzBHFKaBAjHZ+521KKaXu0vorQbTr3I/9s0fi4eFJvoGVaNysLK+X8MKYzPf1\n3ImZKBYBnYwx3wPVgCs6P6GUUnfnMtBm+iKW9exC0Hm77p9f4zaMbFeYQnm8H8gx3JYojDHfAXWA\nHMYYf6AvkBZARCYAvwPPAoeAYOA1d8WilFIpTRQweP8JxrzxHmfWLAAgW6EyDBs7nnaNHn+gx3Jn\n1VPrO9wvQEd3HV8ppVKq1VHC5ztC2fVaB85s/4M0Xj407/QpM794Hy+vtA/8eMluPwqllEqtTgE9\nT4YQsiacfBej8G3SF99M3vw4aQR+JQu77bjJoupJKaVSszDgkzOXqNa0A8ufbkTWgEg8M3nQ641K\n7F35s1uTBOiIQimlkiwBFjkc9Bz5HScGfEDIlTMYD08KZNrPRy/VwCuNSZA4NFEopVQStA94d9N+\ndrXvxPmtSwHI98ijzJwygSdrVUzQWPTUk1JKJSFXgO4RwtOdP2flYxU4v3UpXj6Z6TFgDMd3r03w\nJAE6olBKqSTBgV1JdeTRcEqvCibH0WuciAileoPWfDdlOIUL5Em02DRRKKVUIvsX6HL0DMzbQTXf\nKgA82bobPd5sQKsX6iZucGiiUEqpRPMf0DMiin8GTuT8sI/x8EhDmYHr+N+T+ahb1htPj8RPEqCJ\nQimlElwYMBIY9c9Wwt55l4D96wAoWelJPnw2LWUeTpeo8d1KJ7OVUiqBCPArUP7CNca81I3T9R8l\nYP86fDLn4qvRs9izaSllHk56WynoiEIppRLAfqCbCIf3hRP4YlP+2/U3GMMzzdszY8JgcuXImtgh\nxkkThVJKudFVYADwTUAk1VcG88TpSP6r1wUTfJ5JE8bz7FOPJXaId6SJQiml3MABfAN8HBJBml7D\nybXzCHlafIFvekOfd5+myrBGeHp6JnaY8aKJQimlHrD1QBfg+II1hL33DpdP7ASgTds36fxSZXy8\nk9f0cPKKVimlkrDTQDvgyZMB/Nf4Tc42e5zLJ3aSJWcBJs9cQM+2VZNdkgBNFEopdd/CgSHAI1HC\nssEzcZQtjf9vU/EwnrR67X2OH97Dm682Seww75meelJKqfvwO9AVuHo6gqdWBLNr4WJCr56jWOnq\nfDNtAjWrlU/sEO+bJgqllLoHB4BuwNIrIZT79TC1rzwEwDNtBvC/5nX4uPsbeHikjJM2miiUUuou\nXAUGASNFyDVjMek+6sxBDBU+WUnjRzPxTKWieKUplthhPlApI90ppZSbXS93fQSYtPcUueq25tTr\nz3D17CG80xrerHmNJo/6JNhmQglJE4VSSt3BBqAG8EZYFN49RxNSuQynVvyAZ9p0vN21HycO7aBa\nxRKJHabb6KknpZSKwxngI+w+EQWPhpOn+Qsc3/oHAH5V6zN7xjj8SqfcBHGdjiiUUuoW4cBQ4GFg\n7rUoGvxxjQZ/BFKsbCMyZMnN6Ilz2L5+SapIEqAjCqWUuskf2HLXg1FCwdHzeGjDMQrWeoN0aeGT\n7q9TdfSrZMmcKbHDTFCaKJRSCjiILXf9Dcix8TAPvduF45t+xz+NN880aEinFmXImsEDSJ+4gSYC\nTRRKqVTtGrbcdQRgroVRvMdwjk37jMjwILzSZaR7r370frU0np6p90y9JgqlVKrkAL4FegJnRMj/\nwyqCP3yXQ/67AXisXjO+nfo1RQrlT8wwk4TUmyKVUqnWRqAm0BYIvRhJ6wXXcPTvw0X/3WTLXYhv\nf1jEmqXzNUk46YhCKZVqnAV6A9MAz3AHtVaeo9QhL8QBT736FZycz9ihffD19U3kSJMWTRRKqRQv\nHBiN3WnuKpDv751Il04ciYKSnX+iTtl0vFCtCr7pHk3cQJMoTRRKqRTtT2y5637A53wQfl0HsvvH\nETgiw/HJmI1Xq17kiUdTx/UQ90rnKJRSKdIh4HngGeBAlFB+/K+kKVuOnXO+xBEZTsMX2nL08H5N\nEvHg1kRhjGlojNlvjDlkjOkVy/0FjTH/GGO2GmN2GGOedWc8SqmULxC77EYZ4Beg0H/hPFLvVba/\n+xxXzx0hb8GS/Pbncv74eQa5cuZI3GCTCbedejLGeAJjgacAf2CjMWaRiOyJ0e0T4EcRGW+MKY3d\nA6Swu2JSSqVcAswGemC3JPUOdfD6vyF47A1jS4YCpPFKT8duH/PVgA/x8vJK3GCTGXfOUTwKHBKR\nIwDGmO+BJkDMRCHA9WvhMwP/uTEepVQKtQnoAvwLIEL1BRvJsfIYHiXq4+kBvXr2oNyIt3ikRNHE\nDTSZcmeiyAecjNH2B6rd0qcfsMQY0xnwBerH9kTGmPZAe4CCBQs+8ECVUsnTOW6UuwpQ5Pglsnb+\nlPW/jsfbNxsfjd/IW40KkDerJ5A1UWNNzhJ7Mrs1MENE8gPPArOMMbfFJCKTRKSKiFTJmTNnggep\nlEpaIrBLbpQApgJe4Q6eGfw95yqWZcsvYwF4vtlLdH0+mzNJqPvhzhHFKaBAjHZ+520xvQE0BBCR\nf40x6YAc2C8KSil1myXAe8A+Z/vp1Qc52Lkzf2xbDECRRyoxa/pEataoklghpjjuHFFsBEoYY4oY\nY7yAl4BFt/Q5AdQDMMaUAtIB590Yk1IqmTqMneR8GpskylyL4pPfr7L5lZYc2bYY7/SZ6Pf51xzc\nvUGTxAPmthGFiEQaYzoBiwFPYJqI7DbGDAA2icgi4H1gsjGmG/YUYzsREXfFpJRKfgKBz4Fh2Cus\nM0YJ724L5trmMM5EQq2WA7i8axazpn5N/nwPJW6wKZRJbp/LVapUkU2bNiV2GEopNxNgDrbc9Xo5\nZKvdZ9jfuSchYcLjr4ykcjEvWtX0ce4ToVwxxmwWkXsaaukSHkqpJGcLttx1jbP9aEgUhftPZeHY\n3oQGBuCZxosxw/tRv5qWuyYETcNKqSTjPLYOvgo2SeQSoftv2zlVsTY/fvk2oYEBlK30BFu2btMk\nkYA0USilEl0EMBJb7joZO6n5XkAEpV/sycgmVTm1fw2+mbLz9bjp7Ni0nHJlSyVqvKmNnnpSSiWq\nv7Dlrnud7YYRQrNNIWzeHsp//qdwREXQpOXrTB3/FdmzZ0/ESFMvTRRKqURxBFv2uMDZLga8vf4Y\ne5f6syFraQzQtdfnlMjYgfpPPp5ocSpNFEqpBBYEfAEMBcKwa/f0uBzOzt6j+Hj6AHyz5KXzsNW0\nq5eVormzAYUSM1yFJgqlVAIR4HvgQ24s0fC/KKHsj/8y/KOOnDu+DYCSDz9Ox/qQO5d+PCUV8ZrM\nNsZ4GWOKuzsYpVTKtBV4AngZmyQqA7MPBHCg8Tt89MrjnDu+jaw58jFz9jzWLv+V3Ll0Tbek5I4p\n2xjTCBgOeAFFjDEVgL4i0tTdwSmlkrfz2E1nJmNHFDmBAaEO0q0NpnObOlw8tQvj4UmbN95jzPCB\nZMyYMVHjVbGLz9huAHZ58H8ARGSbji6UUq5EAOOBvsBl7AdNJxEa7Q/nt7XBBIYK5ep14NSmGcz+\nZhJVq1RM1HiVa/FJFBEictkYE/O25LXuh1IqwSzFlrte36GsAdDrTAhDPvyStYGGck915pGH0tB/\nxNvkztwBT09dBjypi0+i2GuMeRHwMMYUwV5Zv869YSmlkpuj2HLXn53tosCQCGH3lKU0H9iZS6f3\n45nGm74fvMYzjxXgli+fKgmLz2R2J+zckwP4CVvR9p47g1JKJR9BQB+gFDZJ+GJXe5245T/61XuV\nPu824NLp/eTJX5wFCxfxbM2CmiSSmfgkiqdFpKeIVHT+9AKecXdgSqmk7Xq5a0lgIPYb5CvA+quR\n7Ok2nsZP+LFz1Ww803jR+f1POXpwJ42fbZCYIat7FJ9TT59gRxIxfRzLbUqpVGIb9hz0Kme7EjAy\nSgjZGcq49cEs+/07woIuUuHROsyeMZ7SpUomXrDqvsWZKIwxT2O3Kc1njBke465M2NNQSqlU5gLw\nKTAJ+yGQA3uVddXDV5i55AxXJSdgeOvDkeRhF2+/8aqeZkoBXI0ozgG7gFBgd4zbrwG93BmUUipp\niQQmYJPEZezqrl2BD0IdDB+5kO5Du5ExRyFe/XgBrzzhi1+hSthxhkoJ4kwUIrIV2GqMmS0ioQkY\nk1IqCVmGrV7Z5WzXB0aKcGjlUeq+342DmxcBkC1rRjrXjyRfXq9EilS5S3wms/MZY743xuwwxhy4\n/uP2yJRSieoY0AKoh00SRbBVTVPPh9P7rSG0bFieg5sX4ZXOl74Dh3Bo71by5dWlN1Ki+ExmzwAG\nYRd7fAZ4Db3gTqkUKxj4EvgKe97ZB1u90ilCWLIxiGpt6nPm8HoAnqj/PDOnjKJQIV3hNSWLz4jC\nR0QWA4jIYRH5BC2PVSrFEeBHbLnrAGySeBnYDzQ+Fs7n319h8bZw8pWsS7Zc+flh7s+s+GuhJolU\nID4jijBjjAdw2BjTAbv4o67cpVQKsh07D7HC2a4IjAJKXY2kx+ffcjwAilR8nvzZPek29hMKZv+Y\nDBkyJFq8KmHFJ1F0w15s2QX4DMgMvO7OoJRSCSMAW8k0kRvlrp8B7aKEOb/v4eVenTm55x/SZ8xB\nxzZP83zNPHh6aLlranPHRCEi652/XgNeBTDG5HNnUEop94rEJodPgUvYctcuQD/g9PFAGvYYzMqf\nhxEVEYpPhix89tkgmtTMjYcmiVTJZaIwxlQF8gGrReSCMaYM0BN4EsifAPEppR6w5diksNPZrgd8\nDRQOdTBowmLGD36PK2cPAtC42StMHT+cXLlyJUqsKmmIczLbGPMFMBu7fMufxph+2D0ptgMPJ0h0\nSqkH5jjQEqiLTRKFsevwLBHhyr4wen97kQlfduXK2YPkK/Qwfy75m1/mf6tJQrkcUTQByotIiDEm\nG3AS8BORIwkTmlLqQQjGlrp+yY1y14+wS4IHXIjgi78DOBbgBXjQquMIMgVvZGDfXnh7eyde0CpJ\ncZUoQkUkBEBELhpjDmiSUCr5EGAe8AFwwnnbS9ikkStCGPfDRr7s25nMuUvQ6K3RtHzMh+oPP4Mx\nzyZWyCqJcpUoihpjrq8Qa7D7ZUevGCsizdwamVLqnu3EzkMsd7bLY8tdnwDW7blEyx792PDHOMQR\nSdiVE3Rv6CB/Xh1BqNi5ShTNb2mPcWcgSqn7dxG7idB4bLlrdmy565vAlUAH7wydx7ej3ifwkj8Y\nwyvtOjBmxBdkyZIlEaNWSZ2rRQH/TshAlFL3Lgq79Pcn2GThCXTGlrtmdghLtgTSqf3LHNn6KwDF\nHinPrBkTqVG9WiJFrJKT+Fxwp5RKwlZgTzPtcLafxJa7lgUOn4lg9Ipg/AOiSOOdCe/0GejTdwA9\n3u9MmjT69lfx49b/KcaYhtj/s57AFBEZHEufF7FffATYLiIvuzMmpVKKE8CH2PWZAAoBw4BmQHCo\ng37TVrL1aDi5ilQhRyYPpowfSpEcX5I/v14Cpe5OvBOFMcZbRMLuor8nMBZ4CvAHNhpjFonInhh9\nSmAr9WqKyCVjjBZsK3UHIcAQYLDz9/TYN9EHQDoRlmw8R4+eH7FjxQyy5C7BxB/X06R6ZrzT6jyE\nujd3XD3WGPOoMWYncNDZLm+MGR2P534UOCQiR0QkHLsPe5Nb+rwFjBWRSwAicu6uolcqFRFgPlAK\n6ItNEq2AfTiX4giI5JX3p9G0fjl2LJ+Oh4cnr7zYhOeqeOOdVpfeUPcuPiOKUUBjYAGAiGw3xtSN\nx+PyYS/Su84fuHXm7GEAY8wa7OmpfiLyZzyeW6lUZSd2ddd/nO1y2DdmbSAsQhizYCeD+3Th1D67\n/mu5SjX4dsZE/Pz8EiVelbLEJ1F4iMjxWzZIj3qAxy8B1MGuHbXSGOMnIpdjdjLGtAfaAxQsWPAB\nHVqppO8idvQwHvumy4bdRewt7Jtnx7FwZv1zhfHdnyHo8n/4ZsrGV18OpkP7N/DwiM92M0rdWXwS\nxUljzKOAOOcdOgPx2Qr1FFAgRju/87aY/IH1IhIBHHVusVoC2Bizk4hMwlb/UaVKFd1dT6V4UcBk\nbLlrAPYccUfshkLZgIuBDr5fFcjWo5GAJ0+9/CmeAf8yfvRQcubU7UjVgxWfrxzvAN2BgsBZoLrz\ntjvZCJQwxhQxxnhhVw9YdEufBdjRBMaYHNhTUbpMiErVVgKVsW+yAOwbZCv2itfMDuGHv49Ro/5L\nTBs3GO800PKx9Mwb/Tbzvv9Gk4Ryi/iMKCJF5KW7fWIRiTTGdAIWY+cfponIbmPMAGCTiCxy3tfA\nGLMH+yXqQxEJuNtjKZUSnMSWu/7gbBfElrs2x66hc/C/MLr3Hc+S2f0ID7lC+gxZmD+xB4UeSp9I\nEavUwoi4PpNjjDmM3Tb3B+AnEbmWEIHFpUqVKrJp06bEDEGpByoEGAp84fw9HdALmzR8gKBQByO/\n3cCozztz7qj9v1+zdgNmThtP0aJFEylqldwYYzaLSJV7eewdTz2JSDHs/FllYKcxZoEx5q5HGEqp\nmwl2P4jS2PWZQrD7RezDTmCnF2HlzkBqv9CFT9+uxbmjm8iaIw+z5/zAqn/+1CShEky8yiJEZK2I\ndAEqAVexGxoppe7RbuyVqM2BY4AftvT1R+wV1qcvRjFs4TVmrgzj9NEdIA5ef6sTRw/t4+XWL3JL\nFaJSbnXHOQpjTAbshXIvYa/1WQg85ua4lEqRLmHXqxmLnZTLCgwE3sa+GcMihG9+O8DyXcH4ZitE\nJh8Phn89nqLZg6latWqixa1St/hMZu8CfgG+EpFVbo5HqRQpCpgK9OZGueu72HLX7M4+Ww4F8cGn\nw1n102ByFanCF+N/o3kNH3zTZU2coJVyik+iKCoiDrdHolQKtRq7uutWZ7s2dqXM8s72xUAHX0xe\nxrRhXbl4ajcA5R/OSfNHDb7p9KI5lfjiTBTGmGEi8j4w3xhzW2mU7nCnlGv+QA/gO2e7ALa6qSW2\n3DXKISxcc4ZPP/6IPau+ASBPvsJMnjiWxo10O1KVdLgaUVwv59ad7ZS6C6HY6x8+B4Kx5a49gJ7Y\ncleAw2cimbH0IiO7PErgJX8806SlS9f3GdT/U3x8fGJ/YqUSiasd7jY4fy0lIjclC+eFdLoDnlIx\nCLbSoztw1Hlbc+woorCzHRTq4Kd1IazaE4aQhgp1XyXEfzUzp0+gdOnSCR+0UvEQnxOgr8dy2xsP\nOhClkrM9QAOgKTZJlMV+k5qHTRIiwj/br1CvVS+mfTMbDw94tlI6/vy2PxvXrdAkoZI0V3MUrbAl\nsUWMMT/FuCsjcDn2RymVulzGlruO4Ua56wCgAzfeXKcvRtF31C/8MO59rp4/QobMOZky6GWK5dNT\nTCp5cDVHsQFbyZcfW/Z93TVuFHAolSpFAdOw5a4XsEPzDthrInI4+4RFCLOXHOWLfj04tGk+AEWK\nl+abaRMoli9DIkSt1L1xNUdxFDuKXppw4SiV9K3BrrV//dvS49hNhCrE6LPtSAg9B4xl+Y8DCQ+5\nipd3ej75pA89e3THy8sroUNW6r64OvW0QkRqG2MuYefpou8CRESyuT06pZKQU9jqpTnOdn7sRPWL\n2DcF2GsiflgdxMYDQaz/cxLhIVepXe8Zpk8eS5EiRRIhaqXun6tTT9e3O83hoo9SKV4oMBxb7hoE\neHOj3NXX2SfKIfy67gK/bgyEtJnxSedFny/GUyDDJVq0aK5rM6lkzdWpp+tXYxcA/hORcGNMLex2\nvd9iFwdUKsUS7E5b3bmxm1Yz7Cgi5tjg0OkIPh76Pb9O60n+Uk/Stc94WtX0IVvGegkcsVLuEZ/y\n2AXYbVCLAdOxW5XOcf0QpZK3vUBD4AVskiiDnaybz40kERTqYPj3e6jX4Dl+HN6G4Mun8Qo+wGt1\n0pIto2fiBK6UG8QnUTice1o3A0aLSDcgn3vDUipxXAa6YYfNS4As2InqbcD18YGIsGpXIA1fHUCP\nNlU4sWsxPr6ZGPn1aLZt/pd06dIlTvBKuUm8tkI1xrQEXsV+wQJI676QlEp4Duxw+SPgPHZy+m1s\nuWvMXahPX4pi+pLzDO1ej0v/7QGgSbNWjB8zgrx58yZw1EoljPgkitexKyJ/JSJHjDFFuLHOmVLJ\n3lrs6q6bne1a2FFExRh9wiOF3zaHsHhrKFEOL/IWqYBPmlCmThrH008/ndAhK5Wg7rhnNoAxJg1Q\n3Nk8JCKRbo3KBd0zWz0o/2Erl751tvMBQ7DLEcSsUdpxLIzeX0zD+BYiT/HqPF7am/qlwsmaKR3p\n06dP4KiVujf3s2d2fHa4exyYhS0jN0AeY8yrIrLmXg6oVGILA0ZgN4K/Xu76Afa0k2+MfhcDHYyc\ns4XJQ7ty5uAacuR7hBVrNlO6kO8tPZVK2eJz6mkE8KyI7AEwxpTCJo57ykxKJRYBfsVOVh923tYU\nW+5aNEa/KIfwx8bL9BswiK2LR+OIiiBz1pwM+aw3pQrq+kwq9YlPovC6niQARGSvMUbXIFDJyj6g\nK7DY2S6N3WWu/i39jpyNpM/IhSya8gHXLhwDoE27Nxkx7EuyZdPFCFTqFJ9EscUYM4Ebp3JfQRcF\nVMnEFexqrqOASCAz0B9bnRGzdC8o1MHP60P4e3MA88e8TWhgAMUfKcOMqROpWbNmwgeuVBISn0TR\nAVsU0sPZXgWMdltESj0ADmAGdt7hHHZy7S3gM24udxUR1u4N4cc1gQRHpMHbJwMdPhhCTq9zfPhB\nd9Km1UpwpVwmCmOMH1AM+FlEvkqYkJS6P+uw32w2OtuPYb/ZVLql3+lLUXw5bTWzR71HoXLP0uqN\nXrz8hA/5sr2WkOEqleS5Wj22N3Ynuy1AVWPMABGZlmCRKXWXTgO9gJnO9kPYctfW3FzuGh4pzF15\nlsGD+rJ7+RREHKQ3Qbz3bD+8vOIzyFYqdXG1hMcrQDkRaQlUBd5JmJCUujthwJfAw9gk4YXdUGg/\n8DK3XxPRqts3tG9WgV3/TMIYQ6cu3diza6vuE6FUHFx9fQoTkSAAETlvjInPulBKJajfsNVMh5zt\nJsAw7PnSmC4FOvjmrzMM+6Qt/nvsXlzlKz3KjKkTqVChAkqpuLlKFEVj7JVtgGIx984WkWZujUwp\nF/Zjr4f4w9kuiS13bXBLvyiH8M/OMBZsCCY03BuJCsM3Q2a+/PIL3unwNh4e+v1HqTtxlSia39Ie\n485AlIqPq9iF+kZiy10zYct5QksNAAAgAElEQVRdO3L7SpVHzkYyaPwSAslJ5lzFqFTUi87zZ5An\nhy+5c+dO2MCVSsZcbVz0d0IGopQrDuz8Qy/gLHaI+ya23DXXLX2DQh3MXHySkYN7c2DdHAqVrs2C\nXxdToYg3kDFB41YqJdASD5XkrceWu25wtmtgy10r39JPRPh3Xyj9hkxh5Y99CQu6RJq0XrzavA5l\nC+hGQkrdK7eeoDXGNDTG7DfGHDLG9HLRr7kxRowxun6UinYaaAdUxyaJvNjlAdZwe5I4fSmKD8ds\noPlz9fhrehfCgi5R64kn2b1rJwMH9CNNGv1OpNS9ive7xxjjLSJhd9HfExgLPAX4AxuNMYtirhvl\n7JcReA/7xVEpwrET0wOAQGy5a3dsyeutJ47CI4XfN4ewcO05Zn9Uj4iwILJmz8WokcN45ZVXMMag\nlLo/8Vlm/FFgKnaZnILGmPLAmyLS+Q4PfRS7d8UR5/N8j61e3HNLv4HYMvgP7zJ2lQL9ji13Pehs\nP48tdy0eS99dJ8KZvSKIC9eENN6ZeO7l7mRNc44hX35B1qxZEypkpVK8+IwoRgGNgQUAIrLdGFM3\nHo/LB5yM0fYHqsXsYIypBBQQkd+MMXEmCmNMe6A9QMGCBeNxaJXcHMCWu/7ubD+CHVXEtnfcpUAH\nExceZOLQDylU7hnqPPMy/6vtQ7F3+usIQik3iE+i8BCR47e8AaPu98DOC/iGY09DuyQik4BJYHe4\nu99jq6TjKnYDoZFABLbctS/QCXvKKaYoh7B0axCDhoxm/YLPiAgLIvT8ThZPfgtvXXpDKbeJz7vr\npPP0kzjnHTpjvwDeySmgQIx2fudt12UEygLLnUkoD7DIGPO8iOhepymcA7v7VS/gDLbc9XXgcyC2\nKxyOnI3ky6mrmD+hGwEntwPwbOMmTBg3WpOEUm4Wn3fYO9jTTwWxJexLid+6TxuBEsaYItgE8RJ2\n6R0AROQKkON62xizHPhAk0TKtwFb7nq9eqE69j9Y1Vj6BoU6+G75BUZ80Zs9q6aBCHkfKsiE8aN5\n/vnnEypkpVK1OyYKETmH/ZC/KyISaYzphN1UzBOYJiK7jTEDgE0isuiuo1XJ2hls5dJ0Zzsvtorh\nFW6v0xYR1h8I58e1wVy+GsV/+1fg4eFB1/e6MWBAP3x9dc9qpRKKEXF9yt8YMxm73fBNRKS9u4Jy\npUqVKrJpkw46kpNw7IhhAHANu9RGd+BjYr9O+vSlKL7+YSenrmYgXYZslMibhjIZd1Mwdwb8/PwS\nLnClUhBjzGYRuadr1eJz6mlpjN/TYfejPxlHX6Vu8ge23PX6pFZjbAVDiVj6hkcKC/+9zJAhQ9jy\n5whKVm/BxElTeOwRL4ypkVAhK6VuEZ9TTz/EbBtjZgGr3RaRShEOYkcNvzrbD2Mrm56Jo/+uE+F8\nMXEJv03tzpWz9iqK8oU8qF4ijZa8KpXI7qVcpAixF6YoxTXsQn3DseWuGbHlrp25vdwV7DURk387\nxpQRvTm43n4nKVrsYaZMnkDduvG5XEcp5W7xuTL7EjfmKDyAi9iqRqWiObDrMPXCrtEE8Bq23DVP\nLP2v7xPx3d8nmd2nGmFBl0jr5c3HvXvTq1dPvL29EyhypdSduEwUxo75y3Pj+geH3Gn2W6U6G7Hl\nruuc7WrYyetH4+h/9Gwk364I4sSFKDzSZafiY41IF3mGyZPGU7x4bIt1KKUSk8tEISJijPldRMom\nVEAq+TjLjXJXwY4cvgT+R+zLEgeHOfjunwuMGj6IAmUaULZSLVo/7sMjr0/G29tb5yKUSqLiM0ex\nzRhTUUS2uj0alSyEY7c77I9dgiMtdp2mj7FLcNxKRFh/MJwvxv7Eslk9CLzkz6VDS5k7eCfpvXWf\nCKWSujgThTEmjYhEAhWxS4QfBoKwqy2IiFRKoBhVEvInttx1v7PdCDtx/XAc/c9cimLs/P3MGtOD\n49t/A6BsuQpMmzJJk4RSyYSrEcUGoBJ2pWeVyh3Clrv+4myXwJa7PhtH//BI4Zf11xg2YhQbfxlM\nZHgQ6X0y8PlnA+nUqZNuJKRUMuLq3WoARORwAsWikqBAbpS7hgMZgD7YnaZiK3cFe03EnJXBnDwd\nwNbFI4kMD6LJC80YM/pr8ufPnzCBK6UeGFeJIqcxpntcd4rIcDfEo5IIAWYDPYH/nLe1Bb7ArtEU\nm0uBDqYv/o9d/p54pvWmWIEcDB05jsJ5fGnUqFECRK2UcgdXicIT+wVSS1FSmU3Yctd/ne2qwGhu\n2XUqhiiHsGxHKEPGzGLVj59Qru6bDOj3KfXKpSON54sJEbJSyo1cJYrTIjIgwSJRie4cttx1GnZE\nkRsYDLQh9nJXsNdEjPxuO/MmdOe//SsBSH9tAw0qpNNyV6VSiDvOUaiUL4Ib5a5XsP8pugKfEnu5\nK9hrIn5YcYkxXw9h25IROCLDyZwlG8OHDaFdu3aaJJRKQVwlinoJFoVKNEuwSWGvs90QW830SBz9\nr18TMf33o3z/RWOunrO1Dq+2acfwYUPIkSNHHI9USiVXcSYKEbmYkIGohHUYeB9Y6GwXB0Zgr4uI\nayxw5lIUs1cGse9UJJI2Jzlz5yN3Fi8mTxpP7dq1EyBqpVRi0GL2VCYQW7k0lBvlrp9iy13jWoYv\nPFL4bVMQI0dPInfxWuQrVIIWNXwZ2PwHsmfLhpdXXIWySqmUQBNFKiHAHKAHN8pd22CTxkMuHrfr\nRDgjZq3n16ndOXd0E6Ur1WHq6qVkTO9J7OvCKqVSGk0UqcAWbLnrGme7CrbctbqLx1wOcvDNX+eY\nOmYQu/6ZgDiiyJ3nIfp/1JEM6eKqgVJKpUSaKFKw89iF+qZgRxS5sCOIdsRd7hrlEJbvCmP4hLms\n+K4XQZf/w8PDg3c7deLzzz4jU6a46qCUUimVJooUKAIYh91Z7nq5axfs0huZXTzu+j4Rew+dZPHk\nt4iKDKN8xcpMmTSBKlXuaU92pVQKoIkihfkLW+66x9l+GlvuWtLFY4LDHMxdfZXV+6LAGArkz0+X\nHv0pkseHd999F09PXeVVqdRME0UKcQRb7rrA2S6GLXdtTNzlrtevifj6m39YPON9KjToRMf2bWlc\nJT3eaXsmQNRKqeRAE0UyF8SNctcwwBf4BLuRkKtdp89cimLybyeZM6Ef+9Z8A8CVXd/QrHoHvapa\nKXUTTRTJlADfAx9yY0Pz/2G3InVV7hoeKfy+OZjRE2aydl4fQgMvkCZNWnr0+JBPPvlEk4RS6jaa\nKJKhrdjJ6dXOdmVgFPDYHR6360Q4k385xtxRb3D6gH10rcdrM2nieEqVKuW2eJVSyZsmimTkPPa0\n0mTsiCIn9rTTa8Rd7gr2mogfVgez6XA4UZEZiQg8R9ZsORgxfCht2rTRUYRSyiVNFMlAJDAeW956\nGfuP1tnZzuLicQ6H8M+uMEZN/41MecuTKUs2nq+RhS515lEg/0Nkz57d/cErpZI9TRRJ3N/YdZh2\nO9sNsOWudzpRdPRsJOMXHmb+pN4c2fwTNRq04Zd508ie0RPwc2PESqmURhNFEnUMW+76k7NdFLtv\n9fO43igkOMzB/LWBTJw4kQ0LBxIReo106dLTtH5ZsmXQpTeUUndPE0USNA877xAI+HCj3DWdi8eI\nCBsOhjN6zr8smdGd88e3AvDMs40YN3YMhQsXdnPUSqmUShNFEhIJ9AKGOdvNga+BfHd43JnLUcxZ\nGcSG7Uf4cWB9xBFFnrz5GDtmFE2bNtXJaqXUfXFrojDGNMR+1nkCU0Rk8C33dwfexH5GngdeF5Hj\n7owpqToLtAJWYP9RhmJLYF19xEdECr9vCeHPLaFEOiBvvkI0ataG4vkzM2DAADJmzJgAkSulUjq3\nJQpjjCcwFngK8Ac2GmMWicieGN22AlVEJNgY8w7wFfbzMlX5F2iB3SciD/Aj8PgdHrPrRDjj5u/j\n12k9KFe/Iy2eq0vzGj5keG2qjiCUUg+UO0cUjwKHROQIgDHme6AJN9arQ0T+idF/Hfbi4lRDsJm0\nO3bF11rYJJHXxWMuBzn4bsUVpk8ayZbfhxAVEUJ278u0G/FcAkSslEqN3Jko8gEnY7T9gWou+r8B\n/BHbHcaY9kB7gIIFCz6o+BJVEPA2MNvZ7oZdfiNtHP0dIqzaE8bomf+wbFZ3Lp3eB0CrVi8xYsRw\nt8erlEq9ksRktjHmf9iN12rHdr+ITAImAVSpUkUSMDS3OAQ0A3Ziq5qmAi+56H/qYiSTfj3F9xM/\n4cDabwEoUqQYEyaMo0GDBm6PVymVurkzUZwCCsRo5+fG+nXRjDH1sRux1RaRMDfGkyT8AryK3VDo\nYex1EmXi6Ht9svqPLaEEXY3g5I4/SJM2Lb169qR3796kT58+ocJWSqVi7kwUG4ESxpgi2ATxEvBy\nzA7GmIrARKChiJxzYyyJLgq749xnznZTYAYQ18ai+09FMOK7rYSnLYBnWm8aPJqXlt99y8PFC1Oy\npKttiJRS6sFyW6IQkUhjTCdgMbY8dpqI7DbGDAA2icgiYAiQAZjrrNQ5ISLPuyumxHIBmyH/wi7e\n9wV2efDYapMCQx3MXnaB8aMGs3PpGB5v+iGTR/WjRN60QMOECzoRRURE4O/vT2hoaGKHolSyky5d\nOvLnz0/atHHNeN49t85RiMjvwO+33NYnxu/13Xn8pGAT9sK5E0AO4AfgyVj6Xd9t7qsJi1g680Ou\nBdjLSfzyXnMmidTD39+fjBkzUrhwYS31VeouiAgBAQH4+/tTpEiRB/a8SWIyO6WaAnQEwrG1wvO4\nedLmuvNXohj78yFmjurJ0a0LAShV2o8pkyfw2GN32mUi5QkNDdUkodQ9MMaQPXt2zp8//0CfVxOF\nG4QCnbDVTADvYPevvnVr0sgoYemOUGb9upO5n9cjIjSQdOl96N+vL926dXugQ8fkRpOEUvfGHe8d\nTRQP2DHsVdabsYv4TQDaxtLv6NlIZi4Pwj8givTZilGsZGWKPJSR8ePGUKhQoQSMWCmlXNN1px+g\nxdhtSTcDRbBLc9yaJELDhal/nub51p3YvWc/OTJ50PW5jGxa/Ru///aLJokkwNPTkwoVKlC2bFme\ne+45Ll++HH3f7t27efLJJ3nkkUcoUaIEAwcOROTGpT1//PEHVapUoXTp0lSsWJH3338/MV6CS61b\nt6ZcuXKMGDHinh6/fPly1q5de8+Pbdy4scs+AQEB1K1blwwZMtCpUyeXfVu0aMGRI0fuKZaEcPTo\nUapVq0bx4sVp1aoV4eHht/U5duwY6dOnp0KFClSoUIEOHToAEBwcTKNGjShZsiRlypShV69e0Y8Z\nM2YM06ZNS7DXgYgkq5/KlStLUhMlIgNFxIgN8lkRuRhLvy2HQ+X5d6eLT+bcAkj5avUlNNyRkKEm\nC3v27EnU4/v6+kb/3qZNGxk0aJCIiAQHB0vRokVl8eLFIiISFBQkDRs2lDFjxoiIyM6dO6Vo0aKy\nd+9eERGJjIyUcePGPdDYIiIi7uvxp0+flmLFit3XMfv27StDhgy5p+P/888/0qhRI5d9AgMDZdWq\nVTJ+/Hjp2LFjnP127dolL7zwwl0dPzIy8q7636+WLVvKd999JyIib7/9dqz/H44ePSplypS57fag\noCBZtmyZiIiEhYVJrVq15Pfff4++r0KFCnEeN7b3ELba9J4+d3VEcZ8uYxew+tTZ7o+9qC5rjD6X\nAh0MnL6D559rzKJxrxF85SwVq1Tjm4lD8U6r5+JdMW76ia8aNWpw6pS9TnTOnDnUrFkz+mp4Hx8f\nxowZw+DBdlHkr776io8//jj6OhdPT0/eeeed254zMDCQ1157DT8/P8qVK8f8+fMByJAhQ3SfefPm\n0a5dOwDatWtHhw4dqFatGj169KBw4cI3jXJKlCjB2bNnOX/+PM2bN6dq1apUrVqVNWvW3HbsBg0a\ncOrUKSpUqMCqVavYtm0b1atXp1y5cjRt2pRLly4BUKdOHbp27UqVKlX4+uuvox9/7NgxJkyYwIgR\nI6Kf45dffqFatWpUrFiR+vXrc/bsWQBWrFgR/S25YsWKXLt27aZYNm7cSMWKFTl8+PBNt/v6+lKr\nVi3SpXO1AwvMnj2bJk2aRLffeecdqlSpQpkyZejbt2/07YULF6Znz55UqlSJuXPncvjwYRo2bEjl\nypV5/PHH2bfPLocT1+u4VyLCsmXLaNGiBQBt27ZlwYIF8X68j48PdevWBcDLy4tKlSrh7+8ffV/h\nwoXZsGHDfcUYb/eaYRLrJymNKLaJSDGxgWUVkd9vuT/K4ZDFW65I9Rc+Fs+06QSQDBmzyLhx4yUq\nKirB400uYn4bctd/JFeujygiIyOlRYsW8scff4iISLdu3WTkyJG39c+SJYtcuXJFKlasKNu2bbvj\n6+vRo4e899570e2LFy/edFwRkblz50rbtm1FRKRt27bSqFGj6G/DXbp0kWnTpomIyLp166RevXoi\nItK6dWtZtWqViIgcP35cSpYseduxb/326ufnJ8uXLxcRkU8//TQ6rtq1a8s777wTa/y3jiguXrwo\nDocdGU+ePFm6d+8uIiKNGzeW1atXi4jItWvXJCIiInpEsWbNGqlUqZIcP348zr/T9OnTXY4onnji\nCdmxY0d0OyAgQETsv1vt2rVl+/btIiJSqFAh+fLLL6P7Pfnkk3LgwAERsX+/unXrunwdMe3bt0/K\nly8f68+lS5du6nv+/PmbRm8nTpyIdeRw9OhR8fHxkQoVKsgTTzwhK1euvK3PpUuXpEiRInL48OHo\n2wYNGiRDhw6N9W/zoEcUOpl9j77FrlIYAlQE5mPnJa7zD4hk1vIgtu06xMZfhxIVGUaLF19mzKjh\n5M6dOzFCTpYSY2GvkJAQKlSowKlTpyhVqhRPPfXUA33+pUuX8v3330e3s2bN6qK31bJlSzw9PQFo\n1aoVAwYM4LXXXuP777+nVatW0c+7Z8+NVfyvXr1KYGDgTSOVmK5cucLly5epXdsusda2bVtatmwZ\nff/1570Tf39/WrVqxenTpwkPD4+u369Zsybdu3fnlVdeoVmzZuTPnx+AvXv30r59e5YsWcJDDz0U\nr2PE5vTp0+TMmTO6/eOPPzJp0iQiIyM5ffo0e/bsoVy5cje9lsDAQNauXXvT6wwLC3P5OmJ65JFH\n2LZt2z3HHJu8efNy4sQJsmfPzubNm3nhhRfYvXs3mTLZdRsiIyNp3bo1Xbp0oWjRotGPy5UrV/Ro\nyN301NNdCseWvr6KTRLtgDXcSBLhkcLMJacY+OMVjpyNokChovTsO4y//vqLuT/M1iSRDKRPn55t\n27Zx/PhxRISxY8cCULp0aTZv3nxT3yNHjpAhQwYyZcpEmTJlbrv/bsQsa7z1qnRfX9/o32vUqMGh\nQ4c4f/48CxYsoFmzZgA4HA7WrVvHtm3b2LZtG6dOnYozScRHzGO60rlzZzp16sTOnTuZOHFidOy9\nevViypQphISEULNmzegPtbx585IuXTq2bt16z7GB/Xe6fqyjR48ydOhQ/v77b3bs2EGjRo1u+hte\nfy0Oh4MsWbJE/422bdvG3r17Xb6OmPbv3x99Ou3Wn5inAwGyZ8/O5cuXiYyMBGwiypfv9v0qvb29\nyZ49OwCVK1emWLFiHDhwIPr+9u3bU6JECbp27XrT40JDQxNsvTdNFHfBH7u87VjAC7tI1TTg+j/V\n7hNhNH1nLO2b+XFg3Y/UKevNgNaZ+eyTjtSvn+IvQk9xfHx8GDVqFMOGDSMyMpJXXnmF1atXs3Tp\nUsCOPLp06UKPHj0A+PDDD/n888+j3+QOh4MJEybc9rxPPfVUdPIBoucFcufOzd69e3E4HPz8889x\nxmWMoWnTpnTv3p1SpUpFf8g0aNCA0aNHR/e70zffzJkzkzVrVlatWgXArFmzokcXrmTMmPGm+YYr\nV65EfwB+88030bcfPnwYPz8/evbsSdWqVaMTRZYsWfjtt9/46KOPWL58+R2PF5dSpUpx6NAhwI6e\nfH19yZw5M2fPnuWPP2LdsYBMmTJRpEgR5s6dC9hT79u3b3f5OmK6PqKI7SdLliw39TXGULduXebN\nmxf9nDHnVK47f/48UVFRgP3icfDgweiRwyeffMKVK1cYOXLkbY87cOAAZcuWdf1HelDu9ZxVYv0k\n1hzFMhHJ5QyigIhsiHHf1eAoGTBlg+QpVkOwZ0vkuaatEiXOlCApVT2J2HPtM2fOFBGRHTt2SO3a\nteXhhx+WYsWKSb9+/aLPa4uI/PLLL1KpUiUpWbKklCpVSj788MPbnv/atWvSpk0bKVOmjJQrV07m\nz58vInZeomjRolKtWjXp2LHjTXMUc+fOvek5Nm7cKIDMmDEj+rbz58/Liy++KH5+flKqVCl5++23\nbzv2rXMUW7dulWrVqomfn580adIker6kdu3asnHjxlj/Pvv37xc/Pz8pX768rFy5UhYsWCBFihSR\nSpUqyQcffCC1a9cWEZFOnTpJmTJlxM/PT1566SUJDQ29qerp+PHjUrp0aVm3bt1txyhUqJBkzZpV\nfH19JV++fLJ79+7b+sycOVM+/vjj6Hbbtm2lRIkS8uSTT0rTpk1l+vTp0c91/vz56H5HjhyRp59+\nWsqVKyelSpWS/v37i4jE+Trux+HDh6Vq1apSrFgxadGihYSGhoqIyMKFC+XTTz8VEZF58+ZJ6dKl\npXz58lKxYkVZtGiRiIicPHlSAClZsmT0PMjkyZOjn7tixYpy4cKFWI/7oOcoEv2D/25/EjpROETk\nKxHxcAZQT0TOXb/P4ZC/t1yUKs92FeORRgDJki2XzJz17U0fHuruJHaiUMlDcHCwVKtWLcFLXpOC\nLVu2yP/+978479fy2AR0DWgJ9AAcwEfYi+pyAueuRNF7wlaaPFWBTb+PBImizWtvc+TQPl793yu6\nBIVSbpY+fXr69+8fXb6cmly4cIGBAwcm2PG06ikOe7G70O3D7hkxE3u9RGSU8Nu2UH7bFEJoeF7S\nenlTvGQ5Zk6bQI0aNRIzZKVSnaeffjqxQ0gUD7oS7040UcTiR+B17L7WZbG70JUA9vuH0O3TMWQv\n1ZR0GbJRq2xG3v9nMY8UK0CaNPqnVEqlTPrpFkME0AsY7my3BiYDJszBgBmrGPVZFwJO7qB87Z3M\nmTWV0gXSYvddUkqplEsThdMZoBWwEvtHGQZ0EmHV9gt0/aA325ZNBRFy5ClAn64tnElCKaVSPk0U\n2AvmWgKngbzAXKDk1Uje+GwWP0z4iJCrZ/HwTMPb73ZlyBf94n0hklJKpQSpuupJgNFAHWySeALY\n5BBCd4Ty7tA1zPjqdUKunqVMheps2byZcaOGaJJIBXSZcdfcvcz4X3/9ReXKlfHz86Ny5cosW7Ys\nzr4peZlxgM2bN+Pn50fx4sXp0qVL9P+1Dz74wOXf5YG717raxPp5UNdRBIrIyzGeuLuIHDwTKp/N\nvSxvjg2QN8cGyJNNO8rI0RN1Ab8EltjXUegy466P6e5lxrds2SKnTp0SEfs3feihh2Ltl9KXGRcR\nqVq1qvz777/icDikYcOG0cuMHzt2TJ566qk4j6uLAj4AB7Glr7sAX2ByhLB/4p9UHfQeNVsPp1SF\nmrzyhC8V3h2TuIEq3hp30S3PO/ndbPHqV6NGDXbs2AHEvcx4nTp16Nix410tM965c2c2bdqEMYa+\nffvSvHlzMmTIQGBgIGCXGf/111+ZMWMG7dq1i14bqWbNmvz00083LRlRokQJVq9ejYeHBx06dODE\niRMAjBw5kpo1a9507JjLjI8ePZqMGTPSoUMHgoODKVasGNOmTSNr1qzUqVOHChUqsHr1alq3bh09\nMrq+zLinpyfffvsto0eP5vLlywwaNIjw8HCyZ8/O7Nl2TbMVK1bw3nvvAXY5i5UrV94Uy8aNG2nf\nvj3z5s2jWLFi0bdXrFgx+vcyZcoQEhJCWFgY3t43byYc2zLjGzduJCQkhBYtWtC/f3/ALjPeqlUr\n/vrrL3r06EHVqlXp2LEj58+fx8fHh8mTJ1OyZEl++eWXWF/HvRKxy4zPmTMHsIsu9uvXL9b/E7E5\nffo0V69epXr16gC0adOGBQsW8Mwzz1CoUCECAgI4c+YMefLkuecY4yvVJYqFQBvgKvAI0GeLP5+/\n9yG7VtvVPM9smsjcLxuR3ksvmEvtoqKi+Pvvv3njjTcAe9qpcuXKN/UpVqwYgYGBXL16lV27dsXr\nVNPAgQPJnDkzO3fuBG6s9eSKv78/a9euxdPTk6ioKH7++Wdee+011q9fT6FChcidOzcvv/wy3bp1\no1atWpw4cYKnn346esG76xYtWkTjxo2j14EqV64co0ePpnbt2vTp04f+/ftHrysUHh7Opk2bbnp8\n4cKF6dChAxkyZOCDDz6Ijn/dunUYY5gyZQpfffUVw4YNY+jQoYwdO5aaNWsSGBh40/4Sa9eupXPn\nzixcuJCCBQvG+brnz59PpUqVbksSAGvWrKF169bR7c8++4xs2bIRFRVFvXr12LFjR/TqsdmzZ2fL\nli0A1KtXjwkTJlCiRAnWr1/Pu+++y7Jly6hVq1asryOm/fv3x7mq7vLly29a7ykgIIAsWbJEl87n\nz58/zosDjx49SsWKFcmUKRODBg3i8ccf59SpU9Er7sb2+EqVKrFmzRqaN28e59/vQUk1iSIK6AN8\n7mw3C4wk3afjeX1SH8KCL+OZ1psu3XvzRf+eeGuSSDLi+83/QdJlxok+Tny4a5nx3bt307NnT5Ys\nWRLr/Sl9mfE7yZUrF//9998DjSUuqWIy+wLQEJskPETo+Nc+/q1QkzkjuxAWfJlK1euza+dOhg/u\n8//27j846vrO4/jzVQ0Ei3hCRiaF1lRD+RU2/Igt4p0eajsKqIeHRPzR0qn1FLlebXWmPTmlHDeD\n19bjkGLKCSepgD1sc8mgZ9ur6XFFoKYKSMW2Kf6KeoXJBYZTRIjv++PzJVniZrOJ7M+8HzM7s/vd\n74/3vmd33/v9fPf7/j9AszgAAAu9SURBVCb85eL6F28z/sFtJpOONuMtLS3Mnj2b2trak4al4hV6\nm/ERI0Z0XNEu0fLeZvwUehaYDPwnUHawnW/UH+bQ86fT9sc/cObZw1m9dgNNz/yUMaNHZTlSl2u8\nzXhi6W4zfvDgQWbOnMmyZcs+cIwlXqG3GS8tLWXIkCFs374dM6O2tvak5TPZZrxgC4URzqr+U+CN\nduMzDzZw+aP72f/mcUpKhrHi4R/x2r6X+PIX53kDP9etSZMmEYvF2LhxI4MGDaK+vp6lS5cyevRo\nJkyYwAUXXMDChQuBMN6/fPly5s2bx9ixY6moqEj4181FixbR1tZGRUUFlZWVNDY2ArBs2TJmzZrF\ntGnTKC0tTRpXdXU1jz766EnDQytWrKCpqYlYLMa4ceMSFqmu1q1bx913300sFmPnzp3ce++9PS5z\n1VVXUVdX13HN7MWLF3PdddcxZcoUSkpKOuZbvnw5FRUVxGIxioqKuPLKKzueGz58OJs3b+aOO+5g\nx44dJ61/5cqVNDc3s2TJko5f6/v37/9AHDNnzuwoNJWVlUyaNIkxY8Zwww03JC0w69evZ82aNVRW\nVjJ+/Hjq6+sBun0dH8b999/PAw88QHl5Oa2trR3HuxoaGjpyvWXLFmKxGBMnTmTOnDnU1NQwdGgY\ncl21ahW33HIL5eXlnH/++R05PHbsGM3NzVRVVZ2SOHsis2xcbLLvqqqqrOsBtq6OEK5CtxYoadrH\nR2//Cq82PcGUWd9k4Z1/y5xpZzC4uGBrZN7bu3cvY8eOzXYYLscdOXKE6dOns3Xr1o7jN/1FXV0d\nzz33XLcdZBN9hiT92sz6VFkK7tvyZeAi4Advv8d5C5Zx8KIYrzY9wYDiwcy4sJT5lw72IuFcAejP\nbcaPHz+e0ZM5C+pfT08BN5hR/PgvGfz1Bex7fQ8AF07/Czb864OUnTsy+Qqcc3mlv7YZj//XViYU\nxE/r94G/B+YebmfUPzXyVvUltL2+h7PP+QTrNtbzzNN1XiTyTL4NiTqXK9Lx2cn7PYo24Ob3jVdf\nOMq1O97h9IGV/M/4S/mzqZOpWX4fg703U94pLi6mtbWVYcOG+R8NnOsFM6O1tfWkkxtPhbwuFDuB\n63fs5eCCO7l41hKKhpczpXwg//jMUww9M69fWr82cuRIWlpaOHDgQLZDcS7vFBcXn3RG96mQt9+m\nq//vXZb+zVLerP0O7cePsvMjA9m0aROVZQOyHZr7kIqKihKeFeucy460HqOQdIWk30pqlvSNBM8P\nlPTD6Pkdksp6WqcBszY8xV2jJvD62n+g/fhRLp5xM083POxFwjnn0iBt51FIOg34HfBZoIVwkvQ8\nM3sxbp4FQMzMbpN0PTDbzJI2mBk4ZKi9dzicyXr2iNE89L2HqL5melpeg3POFYpcPY/i00Czme0z\ns/eAx4Cu569fA5w4V/5x4DL1cPTyvcMHOa2omGsXfos3mnd5kXDOuTRL5zGKEcDrcY9bgM90N4+Z\nHZd0CBhG6OPXQdKtwK3Rw6Ptx97d8+OV93HGyvvSEngeKaFLrvoxz0Unz0Unz0Wn0X1dMC8OZpvZ\namA1gKSmvu4+FRrPRSfPRSfPRSfPRSdJyXsfJZHOoac3gI/HPR4ZTUs4j6TTgbOA1jTG5JxzrpfS\nWSieBUZJ+qSkAcD1QEOXeRqAL0T35wBPm5+S65xzOSVtQ0/RMYeFwE+A04C1ZvYbSUsIF/luANYA\nP5DUDPwvoZj0ZHW6Ys5DnotOnotOnotOnotOfc5F3rUZd845l1kF0RTQOedc+nihcM45l1TOFop0\ntP/IVynk4muSXpS0W9LPJZ2bjTgzoadcxM33l5JMUsH+NTKVXEiaG703fiNpQ6ZjzJQUPiOfkNQo\n6fnoczIjG3Gmm6S1kvZL2tPN85K0IsrTbkmTU1qxmeXcjXDw+w/AecAAYBcwrss8C4Ca6P71wA+z\nHXcWczEdOCO6f3t/zkU035nAFmA7UJXtuLP4vhgFPA+cHT0+J9txZzEXq4Hbo/vjgFeyHXeacnEx\nMBnY083zM4D/AARMBXakst5c3aNIS/uPPNVjLsys0czeiR5uJ5yzUohSeV9AuI7V/cC7mQwuw1LJ\nxZeB75lZG4CZ7c9wjJmSSi4MGBLdPwt4M4PxZYyZbSH8g7Q71wC1FmwH/kRSaU/rzdVCkaj9x4ju\n5jGz48CJ9h+FJpVcxPsS4RdDIeoxF9Gu9MfN7IlMBpYFqbwvPgV8StJWSdslXZGx6DIrlVwsBm6S\n1AI8Cfx1ZkLLOb39PgHypIWHS42km4Aq4JJsx5INkj4CPADMz3IoueJ0wvDTnxP2MrdImmBmB7Ma\nVXbMAx4xs+9KupBw/laFmb2f7cDyQa7uUXj7j06p5AJJlwP3AFeb2dEMxZZpPeXiTKAC+IWkVwhj\nsA0FekA7lfdFC9BgZsfM7GVC2/9RGYovk1LJxZeAfwMws21AMaFhYH+T0vdJV7laKLz9R6cecyFp\nEvB9QpEo1HFo6CEXZnbIzErMrMzMygjHa642sz43Q8thqXxG/p2wN4GkEsJQ1L5MBpkhqeTiNeAy\nAEljCYWiP15rtwH4fPTvp6nAITN7q6eFcnLoydLX/iPvpJiLbwODgU3R8fzXzOzqrAWdJinmol9I\nMRc/AT4n6UWgHbjbzApurzvFXHwd+BdJdxIObM8vxB+WkjYSfhyURMdj7gOKAMyshnB8ZgbQDLwD\nfDGl9RZgrpxzzp1CuTr05JxzLkd4oXDOOZeUFwrnnHNJeaFwzjmXlBcK55xzSXmhcDlHUruknXG3\nsiTzlnXXKbOX2/xF1H10V9TyYnQf1nGbpM9H9+dL+ljccw9LGneK43xW0sQUlvmqpDM+7LZd/+WF\nwuWiI2Y2Me72Soa2e6OZVRKaTX67twubWY2Z1UYP5wMfi3vuFjN78ZRE2RnnKlKL86uAFwrXZ14o\nXF6I9hz+W9Jz0W1agnnGS/pVtBeyW9KoaPpNcdO/L+m0Hja3BSiPlr0suobBC1Gv/4HR9GXqvAbI\nd6JpiyXdJWkOoefW+mibg6I9gapor6Pjyz3a81jZxzi3EdfQTdJDkpoUrj3xrWjaVwgFq1FSYzTt\nc5K2RXncJGlwD9tx/ZwXCpeLBsUNO9VF0/YDnzWzyUA1sCLBcrcB/2xmEwlf1C1Ru4Zq4KJoejtw\nYw/bvwp4QVIx8AhQbWYTCJ0Mbpc0DJgNjDezGLA0fmEzexxoIvzyn2hmR+Ke/lG07AnVwGN9jPMK\nQpuOE+4xsyogBlwiKWZmKwgttaeb2fSolcci4PIol03A13rYjuvncrKFh+v3jkRflvGKgJXRmHw7\noW9RV9uAeySNBH5sZr+XdBkwBXg2am8yiFB0Elkv6QjwCqEN9WjgZTP7XfT8OuAOYCXhWhdrJG0G\nNqf6wszsgKR9UZ+d3wNjgK3RensT5wBC25b4PM2VdCvhc11KuEDP7i7LTo2mb422M4CQN+e65YXC\n5Ys7gT8ClYQ94Q9clMjMNkjaAcwEnpT0V4Qrea0zs2+msI0b4xsIShqaaKaot9CnCU3m5gALgUt7\n8VoeA+YCLwF1ZmYK39opxwn8mnB84kHgWkmfBO4CLjCzNkmPEBrfdSXgZ2Y2rxfxun7Oh55cvjgL\neCu6fsDNhOZvJ5F0HrAvGm6pJwzB/ByYI+mcaJ6hSv2a4r8FyiSVR49vBv4rGtM/y8yeJBSwygTL\nHia0PU+kjnClsXmEokFv44wa2v0dMFXSGMLV294GDkkaDlzZTSzbgYtOvCZJH5WUaO/MuQ5eKFy+\nWAV8QdIuwnDN2wnmmQvskbSTcF2K2uifRouAn0raDfyMMCzTIzN7l9Bdc5OkF4D3gRrCl+7maH2/\nJPEY/yNAzYmD2V3W2wbsBc41s19F03odZ3Ts47uErrC7CNfHfgnYQBjOOmE18JSkRjM7QPhH1sZo\nO9sI+XSuW9491jnnXFK+R+Gccy4pLxTOOeeS8kLhnHMuKS8UzjnnkvJC4ZxzLikvFM4555LyQuGc\ncy6p/wdNrgK0OyTT2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ea2389710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 Score: 0.523\n",
      "Category 2 Score: 0.502\n",
      "Category 3 Score: 0.513\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4V4wAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ea236ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_path = sys.argv[1]\n",
    "thresh = 0.5\n",
    "\n",
    "# get ground truth labels for test dataset\n",
    "truth = pd.read_csv('dermatologist-ai/ground_truth.csv')\n",
    "y_true = truth.as_matrix(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "# get model predictions for test dataset\n",
    "y_pred = pd.read_csv(\"predictions.csv\")\n",
    "y_pred = y_pred.as_matrix(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "# plot ROC curves and print scores\n",
    "plot_roc_auc(y_true, y_pred)\n",
    "# plot confusion matrix\n",
    "classes = ['benign', 'malignant']\n",
    "plot_confusion_matrix(y_true[:,0], y_pred[:,0], thresh, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reference:\n",
    "\n",
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
